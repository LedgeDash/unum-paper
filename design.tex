\section{Design}

\begin{figure*}[t]
	\centering
	\begin{subfigure}[t]{0.8\textwidth}
	\centering
		\includegraphics[width=0.8\columnwidth]{figures/unum-arch-compile-time.pdf}
		% \includegraphics[width=\columnwidth]{figures/architecture.png}
		\caption{Serverless workflows form directed graphs. \name{}
		partitions the graph into an intermediate representation where each
		function is embedded with a configuration that encodes how to
		transition to its immediate downstream nodes. Developers package user
		function, \name{} config and \name{}'s runtime library together to
		create unumized functions.}
		\label{fig:arch:unum-compile-time}

	\end{subfigure}
	\begin{subfigure}[b]{\columnwidth}
		\centering
		\includegraphics[width=0.8\columnwidth]{figures/unum-arch-centralized.pdf}
		\caption{A typical serverless workflow system drives workflow logic
			using a centralized orchestrator that invokes constituent
			functions and waits for their outputs.}
		\label{fig:arch:centralized}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{\columnwidth}
		\centering
		\includegraphics[width=.7\columnwidth]{figures/unum-arch-runtime.pdf}
		\caption{At runtime, \name{} orchestration logic is decentralized and
			runs in-situ with the user functions on an unmodified serverless
			platform. For synchronization and checkpointing,
			\name{} relies exclusively on a standard datastore of choice, such
			as DynamoDB or Cosmos DB.}
		\label{fig:arch:unum-runtime}
	\end{subfigure}
	\caption{\name{}'s Decentralized Orchestration. \name{} partitions
	orchestration logic at compile time and a \name{} runtime runs in-situ
	with user functions to perform only the orchestration logic local to its
	subsection of the graph.}
	\label{fig:arch}
\end{figure*}

To achieve the objectives in \S\ref{sec:goals}, \name{} utilizes a
design/strategy we call ``\emph{decentralized orchestration}'' where instead
of executing workflow orchestration logic entirely within a centralized
orchestrator, a set of ``decentralized orchestrators'' run \emph{in-situ} with
user functions and each performs only the orchestration logic \emph{local to
its subsection} of the workflow.

Efficiently implementing decentralized orchestration while also preserving the
benefits of centralized orchestrators (\S\ref{sec:bg:orchestrator}) requires
\name{} to solve three key challenges:

\squishenum
	\item Given a workflow written in a high-level description language, how
	to partition its orchestration logic such that it can run in a
	decentralized manner in-situ with user functions?

	\item How to efficiently execute orchestration logic in a
	decentralized manner, esp. when it requiers data sharing and
	synchronization across function instances (e.g., fan-in)?

	\item How to provide exactly-once execution semantics when the
	orchestration logic is decentralized across function instances that can
	crash and retry at any point mid-execution?
\squishenumend

\name{} contributes an end-to-end system that solves the three challenges and
delivers significant cost savings and improved or comparable performance than
a state-of-the-art production orchestrator (\S\ref{sec:eval}).
Figure~\ref{fig:arch} depicts \name{}'s architecture. \shadi{the contrast part
is not very clear. is it essentially a vs b?} \dhl{Can you elaborate on
\emph{why} it is not clear? a is compile time. b and c are both runtime.}

\name{} solves the first challenge \emph{at compile time}, using a frontend
compiler and an intermediate representation (IR). Given a workflow definition
written in a high-level description language, the frontend compiler derives a
directed graph representation where nodes are user functions and edges
represent workflow transitions between functions. Based on the directed graph,
the compiler generates an IR in the form of configuration files, one file for
each node in the graph. A \name{} configuration encodes all the outgoing edges
of a node such that each function in the workflow knows how to transition just
to its immediate downstream nodes.

With the configurations from the IR, \name{} solves the second challenge using
a runtime library that efficiently implements a set of workflow patterns in a
decentralized manner and can run in-situ with user functions. In particular,
the \name{} runtime is made up of an ingress component and a egress component.
Developers package each user function with its assigned \name{} configuration
and the \name{} runtime to create an \emph{unumized} function. When an
unumized function executes, its entry point is no longer the user code but
instead the \name{} ingress. And when user code completes, it returns its
results to the \name{} egress which then interprets its co-located \name{}
configuration and performs the workflow transition.

A critical complexity is to enable data sharing and synchronization across
functions in a workflow invocation. For example, applications might aggregate
the results of multiple upstream functions with a single ``sink'' function
when all of the upstream fucntions complete (commonly called a ``fan-in''). To
this end, \name{} leverages a shared \emph{intermediary data store} that is a
strongly consistent serverless storage (e.g., DynamoDB). Upstream functions
each writes user code output into and synchronizes over the intermediary data
store such that faster functions simply terminate and only the last-to-finish
function invokes the sink function.

\name{} leverages again the intermediary data store to also solve the third
challenge and provide a strong execution guarantee we call
\emph{exactly-one-result}. \name{} uses a checkpointing mechansim to limit the
scope of retries when workflows crash mid-execution and guarantee that even if
there are multiple instances of the same function, concurrent or not, only one
instance's output is taken as the final result and propargates downstream.
When user functions do not produce externally visible side-effects, \name{}'s
exactly-one-result guarantee appears the same as exactly-once semantics.

In the rest of the section, we first describe how the \name{} IR encodes
transitions between functions (\S\ref{sec:ir}), then explains how the \name{}
runtime efficiently executes transitions in a decentralized manner, and
finally we detail \name{}'s checkpointing mechanism and how it ensure
exactly-once execution semantics.

\input{patterns}
\input{ir-design}
\input{runtime}





\subsection{Execution Guarantees}\label{sec:exec-gntee}

An important characteristic of any workflow system is (a) how it deals with  a
transient failure in a constituent step, and (b) what guarantees it makes in
the presence of such faults.
 
Many workflow systems durably persist progress to limit the scope of re-execution after faults
\cite{aws-step-functions, durable-functions, netherite, google-workflows, kappa}.
In \name{}, each function is checkpointed to storage after it
completes. In particular, if a workflow experiences crashes mid-execution,
\name{} does not retry from the beginning but from the node of failure only.

\name{} guarantees \textbf{exactly-once execution}, meaning that each step of
the workflow appears to execute exactly once. FaaS engines already
support automatic retries for functions; however, they only guarantee at-least-once
execution. Strengthening this guarantee requires dealing with the following
subtleties:

\begin{itemize}
	\item Function executions are not always deterministic, each re-execution
	may produce a different result.
	\item Some FaaS engines may detect failures incorrectly, thus multiple
	executions of a function can be in progress simultaneously.
\end{itemize}

Fortunately, we found a way to handle these challenges by taking advantage of
conditional store operations supported by strongly consistent data stores.
Specifically, \name{} guarantees that even if there are multiple function
execution instances, concurrent or not, only one instance's result is taken as
the final result and propagates to the downstream ingress node(s). Other
instances simply discard their results and terminate.

\paragraph{Checkpoints and Synchronization.}%\name{} uses a similar checkpointing technique across all transition patterns. 
After user code completes, the \name{} egress gadget immediately writes a checkpoint file that contains the user code
results to the intermediary data store. The checkpoint is uniquely named with
the instance's name (i.e., the name according the
\name{}~IR's naming scheme (\S\ref{sec:ir:naming}), prefixed by the workflow
invocation's unique session ID) such that the existence of a checkpoint
implies the corresponding function has successfully completed its user
function. The create operation is a conditional write and only succeeds when
the file does not already exist. If there are concurrent duplicate instances,
only one of them will create the checkpoint. The others will receive an error
from the write operation and \name{} runtime will simply terminate the
instance. The instance that successfully creates a checkpoint will proceeds to
executing its egress node and propagate its result to downstream functions.

For nonconcurrent duplicates (e.g., retries), \name{} checks if a checkpoint
exists \emph{before} running its user code. If a checkpoint does not exist,
\name{} goes ahead and runs the user code. Otherwise, \name{} reads the data
from the checkpoint and use that as final result without running user code
again. Then \name{} will run the ingress node to invoke the downstream function.
This is necessary because the duplicate might be a retry whose prior execution
crashed after checkpointing but before running the downstream ingress node. \name{} can
tolerate running a ingress/egress node more than once because of the same protection
against duplicates.

\paragraph{External Side Effects.} In the applications targeted by \name{},
there is no need for functions to directly call external storage services.
Rather, all functions are "side-effect-free": their only effect is to provide
a result. 

%Therefore, the "exactly-one-result" guarantee of the \name{} runtime
%is in fact synonymous with exactly-once execution.

Although it is not currently required by any of our applications, it is
conceivable to extend \name{} in the future to support exactly-once execution even for workflows whose
functions have additional side effects. For example, a store interposition
mechanism (such as used in Beldi \cite{beldi}) could be added to support
functions that require more complex storage interactions than obtaining an
input and producing a result.