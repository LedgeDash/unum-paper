\section{Background \& Motivation}\label{sec:bg}

\begin{table}
  \centering
  \begin{tabular}{|m{0.18\linewidth}|m{0.73\linewidth}|}
    \hline
  \textbf{Workflow} & A directed graph of functions that takes an input and produces one or more outputs. \\
    \hline
  \textbf{Function} & A user-defined FaaS function, linked with the \name{} runtime library. \\
    \hline
  \textbf{Invocation} & An request to the FaaS platform to run a function. \\
    \hline
  \textbf{Execution} & The FaaS platform may attempt to \emph{execute} a function invocation one or more times, and guarantees that at least one execution completes. \\
    \hline
  \end{tabular}
  \caption{\name{} terminology.}
  \label{table:terms}
\end{table}


%\begin{table}[]
%\centering
%\scriptsize
%\resizebox{\linewidth}{!}{
%\begin{tabular}{|l|p{0.05\textwidth}<{\centering}|p{0.06\textwidth}<{\centering}|p{0.05\textwidth}<{\centering}|p{0.04\textwidth}<{\centering}|}
%\hline
% & \textbf{Trigger-based} & \textbf{Driver functions} & \textbf{Orchestr-ators} & \textbf{\name{}} \\ \hline
%\textit{No new services}   &  \cmark & \cmark & \xmark & \cmark \\ \hline
%\textit{Higher-level interface}     & \xmark & \xmark & \cmark & \cmark \\ \hline
%\textit{Exactly-once semantics} & \xmark & \xmark & \cmark & \cmark \\ \hline
%\textit{Pay-for-what-you-use billing}       & \cmark & \xmark & \cmark & \cmark \\ \hline
%\end{tabular}
%}
%\caption{Comparison with existing approaches}
%\label{table:positioning}
%\end{table}


%\begin{figure}[t!]
%    \centering
%    \scalebox{.7}{\includegraphics[width=\columnwidth]{figures/ChainExample.pdf}}
%    \caption{Chaining two functions with triggers, driver functions and
%    orchestrators. In the trigger-based approach, \texttt{F} asynchronously
%    invokes \texttt{G} with \texttt{F}'s result. In the driver functions
%    approach, a driver function first synchronously invokes \texttt{F},
%    usually via HTTP, and after \texttt{F} returns, synchronously invokes
%    \texttt{G} with \texttt{F}'s result. Workflow orchestrators provide
%    higher-level interfaces (e.g., AWS Step Functions state machines) to
%    express function compositions such that \texttt{F}'s code does not contain
%    explicit control-flow logic of invoking \texttt{G}. But architecturally,
%    orchestrators are similar to driver functions: an orchestrator instance
%    invokes \texttt{F}, waits for \texttt{F} to return and then invokes
%    \texttt{G} with \texttt{F}'s result.}
%    \label{fig:chain-example}
%\end{figure}

The basic serverless abstraction is simple and quite powerful. Developers build
``functions'', typically written in a high-level language and packaged as OS
containers or virtual machines, which run short computations in response to a
platform event. Events include storage events (e.g.\ the creation of a new
storage object) or HTTP requests. The platform can scale resources for each
function to respond to instantaneous bursts in events and developers are
absolved from building scalable applications and from reserving resources for
maximum capacity.

For example, a developer builds a function that creates thumbnails from large
images and configures the platform to trigger the function whenever a new image
is uploaded to their object store. When there is a burst of such events---e.g\
if an end-user uploads their whole photo library at once---the platform can
scale by spawning many parallel instances of the function to respond to events
within seconds and reclaim resources when the bust subsides.

This simple abstraction can be used to compose many simple applications with
one or a few functions. For example, developers can chain functions for data
pipelines using triggers. In trigger-based composition~\cite{netherite} each
function in a chain invokes the next asynchronously or each function writes to
a data-store configured to invoked the next function in response to the
storage event. Similarly, developers might use a
``driver-function''~\cite{beldi} to drive more intricate control-flow logic. A
driver function acts as a centralized controller that invokes other functions
in the application, waits for their responses, and invokes subsequent
functions with their responses.

%\subsubsection{Ad-hoc composition: triggers and driver functions}
%
%The original serverless abstraction is designed around developing individual
%functions--a \textit{single} unit of work that can run independently on any
%machine. However, this design does not provide a higher-level interface to
%easily express control-flow logic \emph{between} functions. To build larger
%applications that are composed from multiple functions, early adopters use
%function invocation APIs to exress control-flows in an ad-hoc manner in one of
%the following two ways: \textit{ i. trigger-based}
%composition~\cite{netherite} where functions invoke their immediate downstream
%functions with \emph{asynchronous} triggers, usually via a queue or data
%store, (e.g., a lambda writes to an SQS queue or S3 bucket which in turn sends
%an event to Lambda and triggers the next function), and \textit{ii.driver
%functions}~\cite{beldi} where a single function, similar to the
%\texttt{main()} function of a program, encompasses the control-flow logic and
%invokes other functions \emph{synchronously}. Figure~\ref{fig:chain-example}
%depicts an example of chaining functions with the two approaches.
%
%\shadi{shouldn't the first figure (a) have a storage in the middle?}\dhl{For
%the figure, I was intentionally not showing a storage because 1. the point is
%that it's \emph{asynchronous}, 2. AWS Lambda's async invoke API actually hides
%the fact that it's going over a queue. You simply call \texttt{invoke(data,
%RequestType=Event)}, and that adds an item to Lambda's internal queue, which
%then generates an event that triggers your lambda. I've adjusted the text to
%highlight the \emph{asynchronous} nature and downplay the details about
%storage. Take a look and let me know if it works. If not, we can add storage
%into Figure 1. But my concern with it is that people might think \name{} needs to
%manage similar intermediary data stores while in fact it's managed by Lambda.
%The important feature we care about is just that the invocation is
%asynchronous. We don't actually care that it's going over a storage.}
%\shadi{can we add the "async" keyword on the figure. Right now the figure is very simple. Not sure it is worth having the figure at all. It is not adding much more than what is in the text. One option would be to remove the figure entirely and just rely on text. }
%\shadi{from the figure and text it is not clear what is the diff between
%driver and coordinator. }\dhl{Edited the figure caption. Take a look and let
%me know if it's on point and sufficient? High-level note: I think the missing
%piece in the text is how the different approaches program differently. How
%developers write actual code.} \shadi{The caption is clear but too detailed for a caption. I still don't see much value in the figure unless you can somehow capture the details in the caption in the figure itself. For example, for (a) you can add async on the arrow, for (c) you can add a small box with "app logic" being submitted to the orchestrator depicting the high level API. If this does not make sense, maybe remove the figure?}
%
%\shadi {let's just use trigger based throughout the paper}\dhl{Yes.}





%The original serverless abstraction is designed around individual functions
%and does not provide an interface for programming larger applications with
%many functions. As a result, early adopters use low-level function invocation
%APIs to compose functions in an ad-hoc manner, and there are two primary
%approaches.

%The first approach is called trigger-based or unstructure
%composition~\cite{netherite} where functions invoke each other
%\emph{asynchronously} via storage triggers. The second is called driver
%functions~\cite{beldi} where a single \shadi{driver} function invokes other functions
%\emph{synchronously}. Figure~\ref{fig:chain-example} depicts an example of
%chaining functions with the two approaches. \shadi{shouldn't the first figure (a) have a storage in the middle?} \shadi{from the figure and text it is not clear what is the diff between driver and coordinator. }

Such ad-hoc approaches work ``out-of-the-box'', i.e.\ they require no
additional platform provided infrastructure. However neither is well suited to
complex applications with 10s or 100s of functions~\cite{excamera,
hello-retail}. Trigger-based composition can only support chaining of
individual functions or fan-out from one function to multiple, but cannot, for
example, fan-in from multiple functions to one. As a result, only a limited
class of applications can take advantage of burst parallelism for each
application request. Moreover, trigger-based composition scatters control-flow
logic across each function or in configured storage events, making development
unwieldy when application complexity grows.

On the other hand, driver functions concentrate control flow in a single
function and support arbitrary composition. However, they result in ``double
billing'' since the driver function consumes resources for the entire call-graph
execution despite spending most of its time idly waiting for callees to return.
Furthermore, since most serverless platforms impose modest timeouts on
individual functions driver-functions risks timing out before a call-graph is
complete.

Finally, both ad-hoc approaches require developers to handle function crashes,
retries and multiple invocations gracefully~\cite{aws-lambda-retry,
azure-functions-retry, aws-lambda-async-invoke,
azure-functions-exec-guarantee}. Application typically want to ensure
``exactly once'' semantics~\cite{netherite, beldi, boki,
formal-foundation-exec-gtnee, durable-semantics} for an entire call-graph, but
failures and multiple invocations of individual constituent functions can
subvert this goal without careful consideration.

%Moreover, both approaches suffer from weak execution guarantees of the
%underlying serverless system. Functions can crash mid-execution due to runtime
%or hardware faults which may lead to automatic retries~\cite{aws-lambda-retry,
%azure-functions-retry}. Even in the absence of faults, most serverless
%platforms only ensure at-least-once execution~\cite{aws-lambda-async-invoke,
%azure-functions-exec-guarantee} so a single invocation can trigger multiple,
%potentially concurrent, instances. \shadi{if no failures, why would there be multiple invokes?}

\subsection{\remove{Workflow}\dhledit{Standalone} Orchestrators}\label{sec:bg:orchestrator}

\remove{A common solution to address the needs of complex serverless applications is
to introduce a workflow orchestrator~\mbox{\cite{excamera, gg-atc,
aws-step-functions, google-cloud-composer, google-workflows,
durable-functions}}.  Orchestrators operate similarly to
driver-functions---they drive an application workflow by invoking functions in
the application---but are separate hosted services, usually multi-tenant.
Typically, orchestrators provide a high-level programming interface to
describe applications in terms of their control-flow graph and constituent
functions. They offer a rich set of composition primitives, such as branching,
chaining, fan-out and fan-in, while ensuring exactly-once semantics.}

\dhledit{A common solution to address the needs of complex serverless
applications is to introduce a workflow orchestrator that provides a
high-level programming interface with support for a rich set of composition
primitives (e.g., branching, chaining, fan-out and fan-in)~\cite{excamera,
gg-atc, aws-step-functions, google-cloud-composer, google-workflows,
durable-functions,temporal}. Cloud providers typically offer serverless
orchestrators as a service~\cite{aws-step-functions, google-cloud-composer,
google-workflows, durable-functions}. Alternatively, developers can build
custom orchestrators~\cite{temporal, gg-atc, excamera} and deploy in
long-running VMs alongside their functions.}

\dhledit{Similar to driver-functions, orchestrators operate as
\emph{logically} centralized controllers. They drive a workflow by invoking
the functions and hosting application states such as function outputs and
outstanding invocations. Centralization simplifies support for stateful
patterns. For example, to support fan-in, orchestrator can simply wait for all
branches to complete before invoking the aggregation function.}

\dhledit{However, an important difference of orchestrators is that they are
standalone services. Unlike driver functions, orchestrators are not limited by
function timeouts and can be arbitrarily
long-running~\cite{step-functions-timeouts}. Moreover, as standalone services,
orchestrators can be distributed and employ techniques such as sharding and
replication to provide strong execution guarantees and fault-tolerance. For
example, orchestrators can ensure that workflows appears to execute
exactly-once by choosing one result for each function invocation, even if FaaS
engines only guarantee at-least once execution. Orchestrators can also persist
or replicate states during execution so that in face of orchestrator failures,
applications do not lose executions or retry from beginning.}


While \remove{workflow} \dhledit{standalone} orchestrators are able to address
the needs of complex serverless applications, introducing a new
\remove{platform} \dhledit{standalone} service has significant drawbacks.
Building performant, scalable \dhledit{and fault-tolerant} multi-tenant
systems is hard and orchestrators introduce yet-another potential performance
and scalability bottleneck.

\remove{Moreover, hosting such services can be expensive, as they require
dedicated resources in addition to those allocated to FaaS and storage
systems.  Indeed, we find (Section~\ref{sec:eval}) that, in practice,
production systems limit end-to-end performance and scalability, and cost
developers significantly more than necessary in some cases.}
\dhledit{Moreover, hosting such services can be expensive as they require
dedicated resources. Deploying a custom orchestrator per user risks
under-utilization as it cannot multiplex over many users and users pay even
when orchestrator is not actively in use, breaking the fine-grained billing
benefit of serverless. Provider-hosted orchestrators amortizes this cost but
still incur engineering expenses as they require teams on-call.}

\dhledit{Additional, provider-hosted orchestrators preclude users from making
application-specific optimizations. Each provider typical offers just a single
orchestrator service option. While the interface and implementation of the
orchestrator might efficiently support the needs of many application, it
cannot meet all application needs, resulting in a compromise familiar from
operating systems~\cite{exokernel,spin}, networks~\cite{active-networks,sdn},
and storage systems~\cite{comet,splinter}}

\remove{Indeed, we find (Section~\ref{sec:eval}) that, in practice, production
systems limit end-to-end performance and scalability, and cost developers
significantly more than necessary in some cases.}

\amit{I can't figure out a way to include developer flexibility here cleanly.
I'm in favor of adding it, but also it might be a sort of tacit contribution
that the reader deduces themselves... It could also come out in discussion
instead. I think it's a really good point, but perhaps not as central to the
argument? Not sure...}
%
\shadi{should we give a cost comparison example here? something in the lines of
"For example, the pricing schema of AWS step functions makes running a simple X
app Y times more expensive that running directly on AWS Lambda, and the
developers have no control on this pricing."}


\shadi{" Platform-specific orchestrators force developers to write with
proprietary APIs and locks them in a particular cloud provider." move and
merge into goals or later section}



%Recently, workflow orchestrators have emerged to tackle the challenges of
%large serverless applications~\cite{excamera, gg-atc, aws-step-functions,
%google-cloud-composer, google-workflows, durable-functions}. Orchestrators are
%separate hosted services that execute workflow definitions, invoke constituent
%functions and manage workflow states. Architecturally, they are similar to
%driver functions (Figure~\ref{fig:chain-example}). For every workflow
%invocation, an orchestrator instance invokes a constituent function, waits for
%its result and passes it to downstream functions via invocation. All functions
%invocation are initiated by the orchestrator and all states (e.g., function
%results) pass through the orchestrator.

%Different from ad-hoc composition, orchestrators offer (1). higher-level
%programming interfaces that directly express function interactions and hide
%low-level APIs, (2). a rich set of composition primitives, including
%branching, chaining, fan-out and fan-in, (3). exactly-once semantics for
%workflow execution, and (4). long or no runtime limits.

%While fixing the flaws of ad-hoc composition, the orchestrator design creates
%several important drawbacks that neglect or even compromise key benefits of
%the serverless abstraction: (1). End-to-end performance now also depends on
%the orchestrator service that is separate from the FaaS engine. A slow
%orchestrator can become a bottleneck and nullify the fast autoscale advantage
%of serverless. (2). Serverless computing already offers compute and storage
%building blocks that are highly performant and scalable. Adding yet another
%separate service that is a mixture of compute and storage is repeating the
%difficult and expensive task of developing and maintaining a large-scale system,
%which often requires a dedicated engineering team.(3). Platform-specific
%orchestrators force developers to write with proprietary APIs and locks them
%in a particular cloud provider.\dhl{I'm hesitant to include the 3rd point
%because 1. we can't demonstrate that \name{} solves this problem. 2. while
%it's a benefit, it feels more an engineering problem than a research problem.
%3. FaaS functions are already platform-specific. Lambda, Azure functions, etc.
%all have different propritary APIs.} \shadi{I thought the point here was to be a design goal of "interoperability".}
%\dhl{Yes, but the problem is that current \name{} implementation only works on AWS. So we can't show/prove that we achieved interoperability if we list that as a goal. }

%\section{Goals}\label{sec:goals}
%In this paper, we examine whether we can have the best of both worlds:
%\emph{Can we preserve the advantages of workflow orchestrators while building
%entirely on top of the existing serverless computing abstraction (no
%supplemental services)?}
%
%Table~\ref{table:positioning} compares the current solutions and \name{}.
%Specifically, we aim for a system that requires \textbf{no new services}. The
%system should work in a basic, unmodified serverless environment and not require
%adding any new services.  The system should execute workflows solely as
%event-driven serverless functions, and use serverless storage, when necessary,
%to enable stateful control-flow patterns.
%
%In addition, we aim to preserve the best properties of existing centralized workflow orchestrators:
%
%\squishlist
%    \item \textbf{High-level API \& support for common interactions.}
%    Developers should compose functions with high-level primitives similar to
%    existing workflow orchestrators instead of ad-hoc mechanisms and be able
%    to simply express common control-flow patterns such as chaining,
%    branching, fan-out and fan-in.
%
%    \item \textbf{Exactly-once semantics.} The system must guarantee workflow
%    progress and consistency. Specifically, it must retry constituent functions on transient faults;
%    yet it must record exactly one result\footnote{The result recorded
%    for a function may be an error result, such as when a retry or time limit is exceeded.}
%    for each function,
%    even if there are multiple executions due to retries.% or duplicate invocations.
%
%    \item \textbf{Comparable performance and costs.} The system should have
%comparable costs and performance as the state-of-the-art workflow orchestrators.
%Similarly, it should avoid idle-billing. Users should only pay for the resources
%used rather than idle time wait for other functions to return.
%
%    \shadi{should we call it idle billing throughout the paper instead of
%    double billing? It is not exactly double...}\dhl{Yeah, I like "idle
%    billing" better. Used "double billing" because of prior work. But if we no
%    longer need to mention this problem anywhere else in the paper other than
%    the driver functions section, I think we can just define and explain the
%    problem and then be done with it.}
%
%\squishend
%
%\shadi{in the table, should we have double billing? maybe another term would
%be better?}\dhl{Changed it to pay-for-what-you-use billing}
%
%
%
%
%%In this paper, we examine whether we can have the best of both worlds. We
%%argue that it is possible to preserve the advantages of workflow orchestrators
%%while building entirely on top of the existing serverless computing
%%abstraction without adding any supplemental components.
%%
%%Specifically, we aim for a system with the following objectives:
%%
%%\paragraph{\emph{Purely serverless}} The system should work within the current
%%serverless environment and not require adding any new services.
%%
%%The system should execute workflows solely as event-driven serverless
%%functions, and use serverless storage, when necessary, to enable stateful
%%operations (e.g., fan-in).
%%
%%\paragraph{Higher-level programming interface} Developers should express
%%function compositions with higher-level primitives similar to exising workflow
%%orchestrators (e.g., AWS Step Functions) instead of ad-hoc mechanisms.
%%
%%\paragraph{Supports all common interactions} The system should support all
%%composition patterns commonly used in orchestrators today, including chaining,
%%branching, fan-out and fan-in.
%%
%%\paragraph{Exactly-once semantics} Even if a function executes multiple times,
%%due to retries or duplicate invocations, concurrently or non-concurrently, the
%%final state should appear that the execution happened only once.
%%
%%\paragraph{Avoids double billing} Users should only pay for the resources
%%used. Functions should not synchronously wait for other functions to return.
%%
%%\paragraph{Comparable performance and costs} The system should at least have
%%comparable costs and performance as the state-of-the-art workflow
%%orchestrators.
