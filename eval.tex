\section{Evaluation}\label{sec:eval}

\name{} argues for eschewing centralized orchestration and, instead, relying
only on existing building blocks of serverless platforms---a function scheduler
and consistent scalable datastore. The loss of flexibility and application
control from centralization often enables better performance, more efficient
resource usage, or better scalability.

We, therefore, focus our quantitative evaluation on whether orchestrator
decentralization comes at a reasonable performance and resource overhead. In
particular, we run applications implemented for a state-of-the-art
production workflow orchestrator---AWS Step Functions---both on their intended
target as well as using \name{}. Given the opacity of public cloud
infrastructure, we cannot measure resource usage directly and instead use billed
costs as a proxy.

Specifically, we answer the following questions:


\begin{enumerate}

  \item What overhead does \name{} incur in end-to-end latency and resources?

  \item How well does \name{} support an application that Step Functions cannot support well?

  \item What are the sources of \name{'s} overheads?

\end{enumerate}

% We show that 

% \begin{itemize}

  %     \item over 97\% of \name{}'s latency overhead comes from API calls to
  %     Lambda and data stores, which means the bulk of \name{}'s performance will
  %     automatically improve with the underlying platform (e.g., a faster Lambda
  %     or data store) without any modification to \name{} itself.

  %     % \item The additional Lambda duration billing for executing \name{} runtime
  %     % is negligible across all data sizes

  %     \item \name{} is slightly faster (11-28\%) in chaining performance and
  %     much faster in parallel fan-out and fan-in performance (up to 4.58x),
  %     especially at higher level of parallelism, than Step Functions.

  %     \item \name{} delivers more than one order-of-magnitude cost savings for
  %     almost all applications we evaluated, even when using the more expensive
  %     DynamoDB as the intermediary data store. The applications we use cover all
  %     orchestration patterns that Step Functions currently support.

  %     \item \name{} is able to express all orchestration patterns that Step
  %     Functions currently support. Additionally, with the ExCamera
  %     implementation, we demonstrate that \name{} can express fold or for loops
  %     and support pipeline parallelism, neither of which is expressible in Step
  %     Functions.

  % \end{itemize}

Though we evaluate the applications running on both AWS and Google Cloud, we
focus our discussion on our \name{} implementation on Lambda and DynamoDB,
because it runs on the same serverless infrastructure as Step Functions.

\subsection{Experimental setup}

We run all experiments on AWS with Lambda and DynamoDB, and on Google Cloud
with Cloud Functions and Cloud Storage. All services are in the same region
(\texttt{us-west-1} on AWS and \texttt{us-central-1} on Google Cloud). All
functions are configured with 128MB of memory except for ExCamera where we use
3GB of memory to replicate the setup in the original paper~\cite{excamera,
gg-atc}. Both DynamoDB and Firestore use the serverless option with on-demand
provisioning. Experiments that use Step Functions as baseline run Step
Functions in the same region as well. To avoid performance artifacts related
to cold-starts in comparisons, we ensure all functions are warm by running
each workflow several times before taking measurements.

All but one application were originally written as AWS Lambda functions with
Step Function state machines. For Step Function experiments, we ran them
directly. For \name{} experiments, we first compiled the Step Functions
definitions to \name{} IR, linked the functions with platform-specific runtime
and finally executed them as lambdas or Google Cloud functions. The notable
exception is our \name{} and Step Functions implementations of ExCamera, which
differ due to a limitation in the Amazon State Language. As a result, the more
efficient \name{} implementation is written directly in \name{} IR instead of
compiled from the Step Functions definition (\S~\ref{sec:eval:excamera}).

For the Step Functions experiments, we run the workflows in ``Standard''
configuration~\cite{aws-step-functions-standard-vs-express}, which provides
similarly strong execution guarantees as
\name{}~\cite{aws-step-functions-exec-gntee}.

% We do not consider Step Functions' Express Workflows in our comparison because
% of its weaker execution guarantee, namely the same invocation could result in
% multiple and potentially diverging results if any part of the workflow logic
% is nonidempotent~\cite{aws-step-functions-exec-gntee}.

% Note that even though Step Functions claims that the Standard Workflows
% provides "exactly-once workflow
% execution"~\cite{aws-step-functions-exec-gntee}, it is not clear whether it
% implies exactly-once execution for component functions of the workflows. Our
% interpretation is that the internal states of a standard workflow will appear
% to execute exactly once, but component functions might not run exactly-once
% due to failures and retries, which is identical to \name{}. \shadi{this
  % paragraph is a bit confusing... }

\subsection{Performance}\label{sec:eval:micro}

\name{}'s performance overhead results from the \name{} runtime logic run in
each function as well as API calls to data stores and FaaS engines. We
characterize these overheads by measuring the latency to execute various
patterns consists of \texttt{noop} functions as well as end-to-end performance
of real applications. Overall we find that \name{} performs comparably or
significantly better than Step Functions in most cases owing to higher
parallelism and a more expressive orchestration language, with modest slow
downs in the remaining cases due to implementation deficiencies.

\subsubsection{Chaining}\label{sec:eval:chain}

\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{figures/TotalAdditionalLatencyNBreakdown.pdf}
  \caption{An orchestrator incurs a latency on each transition between
functions. \name{}'s overhead is due to storage operations to ensure
exactly-one-result semantics, Lambda invocation API overhead to enqueue the
next function to run, and additional \name{} runtime code in the function
instance itself for the orchestration logic.}
  \label{fig:single-transition-latency-breakdown}
\end{figure}

For the simple chaining pattern, the \name{} runtime performs a storage read to
check whether a checkpoint already exists, a storage write to checkpoint the
function's result, and an asynchronous function invocation to initiate the next
function in the chain.

Figure~\ref{fig:single-transition-latency-breakdown} shows time to perform each
of these operations for different result sizes. As expected, storage operations
are slower when checkpointed results are larger, but the total overhead from the
\name{} runtime operations is consistently lower than an equivalent Step
Function transition.

\amit{We can keep Figure~\ref{fig:chainmicrolatency} and explain briefly that this
basically confirms the thing, \emph{but} for that to be the case, it should be
the case that the difference between Step Functions and \name{} increases by
50ms for each additional link in the chain. Is this the case? Otherwise, I
think we can elide this figure.}

The \name{} implementation of the IoT pipeline application benefits from this
difference, with the \name{} version running 1.9x faster than the Step Functions
version (Table~\ref{table:macro}).

%\subsubsection{Chaining performance}\label{sec:eval:chain}
%
%\emph{Highlight: Maybe just a repeat of the previous point with a different experiment}
%
%
% \begin{figure}[t]
%  \centering
%  \includegraphics[width=\columnwidth]{figures/ChainMicroLatency.pdf}
%  \caption{End-to-end latency of chaining N functions. All constituent
%    functions in the experiment only run for 1-2ms, so the results mostly
%    reflect the latency of the workflow systems. \name{} is marginally
%    (11-28\%) faster than Step Functions on average. The results show that
%    \name{} is basically as fast in the most fundamental orchestration
%    primitive of transitioning from one function to the next.}
%  \label{fig:chainmicrolatency}
% \end{figure}
%
%
%We evaluate how \name{} performs on executing a series of functions in
%sequence and then compare with Step Functions. We measure the end-to-end
%latency of executing a chain of functions with varying chain lengths (2 to 10
%functions). Our goal is to allow the end-to-end latency to maximally reflect
%the performance of the workflow system, with minimum interference from the
%latency of user code. Therefore, we use a constituent function that simply
%returns its input without any computations to keep the user code runtime
%intentionally short (less than 2ms).
%
%Figure~\ref{fig:chainmicrolatency} shows the end-to-end latency of Step
%Functions and \name{} with DynamoDB. Overall, \name{} is around 43-173ms or
%11-28\% faster in chaining than Step Functions. A plausible explanation for
%the shorter latency is that a transition in \name{} from one function to the
%next involves a single network communication to Lambda when the source
%function calls the target function asynchronously. The same transition in Step
%Functions, however, requires not only an invocation from the orchestrator to
%Lambda but also a network communication from the source function to the
%orchestrator to send back the function output first. \name{} reduces
%the number of network communications because control-flow states and logic are
%decentralized to constituent functions without being managed by a centralized
%orchestrator.

\subsubsection{Fan-out and fan-in}\label{sec:eval:fan-out}

% \emph{Highlight: fan-out doesn't require any additional storage; fan-in requires
% additional reads and more expensive writes; compared to Step Functions, this
% overhead results in slower fan-out/fan-in patterns at low branching factor;
% conversely, \name{}'s parallelism is not limited by the orchestrator, so with
% large branching factors, \name{} is much faster than Step Functions as fan-out
% branches run in parallel.}

\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{figures/MapMicroLatency.pdf}
  \caption{End-to-end latency of a fan-out and fan-in pattern with increasing
branching degree. \name{} is slower at lower branching degrees but significantly
outperform Step Functions at moderate and high branching degree.}
  \label{fig:mapmicrolatency}
\end{figure}

Fan-out requires the same number of storage operations as chaining and similar
orchestration logic, but the \name{} runtime performs an additional asynchronous
invocation at the source function for each branch. For fan-in patterns, each
source branch performs an additional storage read to determine if it is the
final branch to execute, and only the final branch performs the asynchronous
invocation of the target function.

\amit{Why does \name{}'s latency grow at all in \ref{fig:mapmicrolatency}? If it
can do all branches in parallel, shouldn't latency remain roughly constant?}
\dhl{They are not. map invokes each branch in sequence. This is the reason for
unum's worse performance.}

Figure~\ref{fig:mapmicrolatency} shows the latency of a fan-out followed by a
fan-in at varying branching degrees for both \name{} and Step Functions. At
low branching degree, \name{} incurs a modest overhead (up to 200ms) relative
to Step Functions. We believe this is mostly due to our implementation
initiating each branch invocation sequentially. However, at higher branching degrees (as low as 20 branches), Step
Functions limits parallel invocation of concurrent fan-out
branches~\cite{aws-step-functions-map-state} while \name{} is limited only by
Lambda's scalability, resulting in over 4x lower latency with 512 branches.

These differences manifest in real workloads as well. Wordcount is highly
parallel (with 262 parallel mappers and 250 reducers) and performs over 2x
faster on \name{} than on Step Functions (Table~\ref{table:macro}).

% These differences manifest in real workloads as well. Both the Text Processing
% and Word Count applications include an fan-out followed by a fan-in. Text
% Processing has low branching degree and, indeed, performs slightly worse on
% \name{} than on Step Functions (1.8\%). Conversely, Word Count is highly
% parallel and performs 219\% faster on \name{} than on Step Functions.
% (Table~\ref{table:macro})

% \subsubsection{Cost comparison}

% \begin{figure}[t]
  %     \centering
  %     \includegraphics[width=\columnwidth]{figures/TotalCost.pdf}
  %     \caption{Total costs comparison of 1 million state transitions between
    %     Step Functions and \name{}. Computation assumes Lambda size of 3GB. \shadi{colors are hard to read}}
  %     \label{fig:total-costs-single}
  % \end{figure}

% \begin{figure}[t!]
  %     \centering
  %     \includegraphics[width=\columnwidth]{figures/TotalMapCost.pdf}
  %     \caption{Total costs comparison of fan-out and fan-in between Step
    %     Functions and \name{}. Computation assumes Lambda size of 3GB and 1KB data
    %     size for function outputs and checkpoints.}
  %     \label{fig:total-costs-map}
  % \end{figure}

% In this section, we break down the cost of running workflows with \name{} and
% compare with that of Step Functions. We discuss the costs for a single transition,
% chaining and fan-out.

% Costs numbers are calculated based on AWS pricing for \texttt{us-west-1}
% region. We do not "measure" the cost of running workflows because AWS does not
% provide real-time billing data. We scale costs numbers by 1 million to ease
% reading.

% Step Functions charges based on the number of state
% transitions~\cite{aws-step-functions-pricing}. Each state transition is charged
% a fixed rate of \$27.9 $ \times 10^{-6}$.

% There are two parts to \name{}'s costs: (1). additional Lambda duration
% billing for running the \name{} runtime, and (2). data store reads and writes.

% We do not count the storage costs in the intermediary data store because after
% a workflow execution, checkpoints can be immediately deleted or moved to
% cheaper storage by the user.

% Figure~\ref{fig:total-costs-single} shows the total cost of transitions for
% function data size varying between 0-255KB. The computation assumes Lambda
% memory size of 3GB. We can see that the additional Lambda duration costs from
% running \name{} runtime is a small fraction when compared with the costs of
% DynamoDB writes. \shadi{how is the figure showing this? how do you translate lambda duration to cost in the figure? this figure is hard to understand. }
% In fact, even at 255KB, the additional Lambda
% duration costs is only abour \$10. If using the smallest 128MB lambdas \shadi{(instead of 3GB)}, the
% costs diminishes to merely \$0.46.

% DynamoDB writes dominates the costs in \name{} because the on-demand mode
% charges only not on the number of writes but also on the amount of data
% written. For 1KB of data, DynamoDB charges $1.3942 \times 10^{-6}$ for a write
% and $0.279 \times 10^{-6}$ for a read. Because checkpoint reads do not return
% any data when there are no faults, the cost of checkpoint reads does not
% increase with the data size and stays merely \$0.279 for the computation in
% Figure~\ref{fig:total-costs-single}.

% Even though the simulation in Figure~\ref{fig:total-costs-single} shows the
% costs of \name{} outpacing that of Step Functions at larger data sizes, our
% macrobenchmark results demonstrate that functions in real-world serverless
% workflows do not output large amount of data. In fact, workflows tend to use
% their own storage and manage application data manually. Checkpoints in the
% \name{} intermediary data store are normally under 1KB. 

% Figure~\ref{fig:total-costs-map} shows the total costs of fan-out and fan-in
% when function checkpoints are under 1KB. In addition to the costs discussed
% for a single transition, the entry function performing the fan-out incurs
% higher Lambda duration costs for invoking each fan-out function. The fan-in
% function at the end also causes extra costs because it reads the checkpoints
% of all fan-out branches. However, the total costs of this microbenchmark is
% more than 3.2x lower with \name{} than Step Functions.

% \begin{itemize}

  %     \item S3 charges \$5.5 per 1M PUT requests (for checkpoint write) and \$0.44
  %     per 1M GET requests (for checkpoint read).

  %     \item DynamoDB on-demand capcity mode charges reads and writes based on
  %     the data size. 1M requests for writing 1KB data costs \$1.3942 and 1M
  %     requests for reading 1KB data costs \$0.279. Note that in the case of
  %     DynamoDB, if no faults happen during execution, the checkpoint read will
  %     return "item not found", which costs the same as returning 1KB of data.

  %     \item For 1M state transitions, \name{}'s costs for S3:

  %     \[  r(d)\times0.05 + 5.94 \]

  %     and for DynamoDB:

  %     \[  r(d)\times0.05 + d\times1.3942 +0.279\],

  %     where $r$ is the total additional runtime of \name{}, $d$ is the data
  %     size.

  % \end{itemize}



\subsubsection{\remove{ExCamera}}\label{sec:eval:excamera}

% \begin{table}
%   \centering
%   \begin{tabular}{|r|r|}
%     \hline
%     \textbf{ExCamera Implementation} & \textbf{Latency (seconds)} \\ \hline
%     Original        & 76                         \\ \hline
%     \name{}-aws & 84                         \\ \hline
%     gg                       & 90                         \\ \hline
%     Step Functions & 98                         \\ \hline
%   \end{tabular}
%   \caption{ExCamera performance. \name{} is 7.1\% faster than
% gg~\cite{gg-atc} and 10.5\% slower than the hand-optimized implementation.}
%   \label{table:excamera}
% \end{table}

\remove{We compare the performance of an application not well-suited to Step
Functions. ExCamera~\mbox{\cite{excamera}} is a video-processing application
designed to take advantage of high burst-latency on Lambda using using custom
orchestration. We compare the results of the original hand-optimized
implementation as well as another implementation, gg, by the same authors,
with a suboptimal Step Functions implementation as well as an implementation
in hand-written \name{} IR.}

\remove{Using the same experimental setup as the prior work (i.e., encoding
the first 888 chunks of the \texttt{sintel-4k}~\mbox{\cite{sintel}} video
using 16 chunks per batch and Lambdas configured with 3GB of memory), \name{}
is 7.1\% faster than gg~\mbox{\cite{gg-atc}} and 10.5\% slower than the
original, hand-optimized ExCamera (Table~\ref{table:excamera}). The original
ExCamera pre-loads raw video chunks into lambdas before starting, while
\name{} and gg do not. The original authors attributes the comparatively
slower performance of \texttt{gg} to the lack of pre-loading which is likely
also the reason for \name{}'s slower performance.}

\remove{But different from gg, \name{} executes control-flow logic in a
decentralized manner while gg has a centralized coordinator on EC2 that
proxies inter-function communications and invokes lambdas. The reduced number
of network communications explains why \name{} is slightly faster than gg.}

\remove{In comparison, an important limitation of Step Functions is that all
concurrent fan-out branches must complete before any fan-in starts. This means
the Step Functions implementation of ExCamera must serialize the encode and
re-encode stages.  Conversely, \name{}'s IR is flexible enough to support
ExCamera's original pattern where tasks start as soon as their input data
becomes available, because \name{}'s fan-in uses a low-level primitive to
directly express data dependency between functions. Thus, the \name{} ExCamera
allows more parallelism between branches and is 16.7\% faster than Step
Functions.}

\subsection{Cost}

\begin{table*}[t]
  \centering
  \begin{tabular}{|l|rr|rr|}
\hline
                         & \multicolumn{2}{c|}{\textbf{Latency (seconds)}} & \multicolumn{2}{c|}{\textbf{Costs (\$ per 1 mil. executions)}} \\ \hline
\textbf{App} &
  \multicolumn{1}{c|}{\textit{Unum-aws}} &
  \multicolumn{1}{l|}{\textit{Step Functions}} &
  \multicolumn{1}{c|}{\textit{Unum-aws}} &
  \multicolumn{1}{l|}{\textit{Step Functions}} \\ \hline
\textit{IoT Pipeline}    & \multicolumn{1}{r|}{0.12}         & 0.23        & \multicolumn{1}{r|}{\$6.75}              & \$112.02            \\ \hline
\textit{Text Processing} & \multicolumn{1}{r|}{0.52}         & 0.55        & \multicolumn{1}{r|}{\$29.53}             & \$225.29            \\ \hline
\textit{Wordcount}       & \multicolumn{1}{r|}{408.88}       & 898.56      & \multicolumn{1}{r|}{\$7,056.55}          & \$18,141.19         \\ \hline
\textit{ExCamera}        & \multicolumn{1}{r|}{84.52}        & 98.42       & \multicolumn{1}{r|}{\$48,451.53}         & \$114,633.13        \\ \hline
\end{tabular}
  \caption{Application latency and costs comparison between \name{} and Step
    Functions. Running applications on \name{} is 1.35x to 9x cheaper than
    on Step Functions. Furthermore, \name{} is faster than Step Functions
    especially for workflows with high degrees of parallelism.}
  \label{table:macro}
\end{table*}

\begin{figure}[t!]
    \centering
    \includegraphics[width=\columnwidth]{figures/AppCostBreakdown.pdf}
    \caption{Step Functions state transitions dominate the total costs for all
    applications (99.5\% in IoT Pipeline, 99.4\% in Text Processing, 80.0\% in
    Wordcount, 72.2\% in ExCamera). While \name{} runtime cost is also the
    majority, it accounts for a smaller portion of the overall costs (95.7\%
    in IoT Pipeline, 97.8\% in Text Processing, 72.5\%
    in Wordcount and 61.0\% in ExCamera).}
    \label{fig:cost-breakdown}
\end{figure}

One of the main attractions of building applications on serverless platforms
is lower cost. In particular, because resources are easy to reclaim,
applications are charged only for resources used to respond to actual events
or requests. Thus, applications with potential for high burst-parallelism, or
with intermittent bursts of concurrent requests, can achieve high performance
without incurring the cost of long-term provisioning for max capacity. As a
result, the \emph{cost} of orchestration overhead matters as well as
performance.

The source of costs for \name{} and Step Functions is quite different. Step
Functions imposes a cost to developers, in addition to running Lambda
functions, for each workflow transition. This abstracts the underlying, likely
shared, costs to run the Step Functions servers, persist state and checkpoint
data. Conversely, \name{} incurs costs directly from those services:
additional Lambda compute time and DynamoDB storage on AWS.

Figure~\ref{fig:cost-breakdown} shows the cost to run each application using
\name{} broken down to each component: data store costs for writing and
reading checkpoints, data store costs for writing coordination sets, data
store costs for deleting checkpoints and writing coordination sets for garbage
collection, Lambda invocation, and Lambda CPU-time for both the \name{}
runtime and user function. Storage costs, using DynamoDB, are the largest
portion of overall cost and costs for writing to DynamoDB is the
majority\footnote{Writes in DynamoDB cost one order-of-magnitude more than
reads}. This includes writing checkpoints, writing to coordination set (either
for fan-in for garbage collection) and deleting checkpoints for garbage
collection.

Nonetheless, \name{} is consistently cheaper than Step Functions for all
applications we tested. Table~\ref{table:macro} shows the price to run each of
the applications we implemented based on public pricing information for AWS in
the \texttt{us-west-1} region using \name{} and Step Functions.


%Table~\ref{table:macro} are calculated based on public pricing information for
%AWS \texttt{us-west-1} region. We do not ``measure'' the costs of running
%workflows because AWS does not provide real-time billing results for all
%services.
%
%For Step Functions, the total costs of running an application consists of i.
%Lambda duration billing for running user code, ii. Lambda invocation billing
%for starting functions and iii. Step Functions state transition
%charges~\cite{aws-step-functions-pricing}. Step Functions charges a fixed rate
%of \$27.9 $ \times 10^{-6}$ per state transition. A state transition equates
%to an edge in the workflow graph in the case of chaining and fan-out. But
%fan-in only counts as one state transition. Additionally, Step Functions adds
%a \texttt{Start} and \texttt{End} state to each workflow that counts towards
%state transitions.
%
%The total costs of running an application with \name{} consists of i. Lambda
%duration billing for running the \emph{unumized} functions, that is both the
%user code and \name{} runtime code, ii. Lambda invocation billing for starting
%functions, and iii. data store reads and writes for checkpoints. DynamoDB
%charges $1.3942 \times 10^{-6}$ for writing and $0.279
%\times 10^{-6}$ for reading 1KB of data. We do not count the costs of storing
%the data in DynamoDB because after a workflow execution, users can immediately
%delete the checkpoints or move them to cheaper storage.

%Step Functions state transitions dominate the total costs of running
%applications, accounting for 72.2\% in ExCamera, 79.6\% in Wordcount and over
%99\% in IoT Pipeline and Text Processing. While \name{} runtime and checkpoint
%costs are also the majority in IoT Pipeline (87.2\%) and Text Processing
%(89\%), for large-scale workflows, \name{} only accounts for 18.1\% of the
%costs in ExCamera and 24.8\% in Wordcount.
%
% A cheaper data store that supports strong consistency and
%conditional updates can significantly reduce the cost of using \name{}. For
%instance, Cosmos DB charges $0.279 \times 10^{-6}$ (or one fifth of the write
%cost of DynamoDB) per 1KB for both reads and writes~\cite{cosmosdb-pricing}.

%While pricing of a particular service can change based on a multitude of
%factors, the amount of developement efforts and the size of going workloads
%that has already gone into Lambda and multi-tenant storage systems likely
%means that they are much more resource efficient than a specialized
%orchestrator service such as Step Functions. The resource efficiency advantage
%is likely going to persist given the bigger pool of users and applications for
%Lambda and DynamoDB as they are more fundamental services. Therefore,
%\name{}'s cost benefits are likely going to continue and become even larger as
%FaaS systems and serverless data stores continue to improve.

Of course, developer-facing pricing does not necessarily reflect \emph{actual}
costs and is only a weak proxy for resource utilization. However, it is clear
that, in practice, \name{}'s overheads do not result in unreasonable costs and,
in fact, often results in lower costs to the developer than Step
Functions---AWS's native workflow orchestrator. This suggests that at least
applications that currently run on Step Functions could afford to run using
\name{} instead.

Moreover, \name{} costs benefits from improvements to underlying infrastructure
or different pricing schemes. For example, Azure's Cosmos DB provides similar
performance and consistency guarantees to DynamoDB but charges 5x less to
perform a write operation (the dominant constituent of \name{} storage cost on
AWS).


\majoredits{\subsection{Case Study: ExCamera}\label{sec:eval:excamera}}

\begin{table}
  \centering
  \begin{tabular}{|r|r|}
    \hline
    \textbf{ExCamera Implementation} & \textbf{Latency (seconds)} \\ \hline
    Original        & 76                         \\ \hline
    \name{}-aws & 84                         \\ \hline
    gg                       & 90                         \\ \hline
    Step Functions & 98                         \\ \hline
  \end{tabular}
  \caption{ExCamera performance. \name{} is 7.1\% faster than
gg~\cite{gg-atc} and 10.5\% slower than the hand-optimized implementation.}
  \label{table:excamera}
\end{table}

\majoredits{ExCamera~\mbox{\cite{excamera}} is a video-processing application
designed to take advantage of high burst-scalability on Lambda using custom
orchestration. We compare our \name{} implementation with three others: (1).
the original hand-optimized ExCamera using the mu framework, (2). gg which is
another implementation by the same authors, and (3). a suboptimal Step
Functions implementation that we wrote.}

\majoredits{Both gg and mu employ standalone orchestrators to proxy
inter-function communications, store application states and invoke lambdas.
However, mu uses a fleet of long-running identical lambdas where all
application code is co-located and raw video chunks are pre-loaded, whereas gg
lambdas are event-driven, task-specific and cannot leverage pre-loading.
Nonetheless, the application logic are identical for gg ExCamera and mu
ExCamera. \name{} ExCamera replicates the application logic exactly. On the
other hand, the Step Functions ExCamera had to serialize the encode and
re-encode stages because the Map pattern requires all concurrent branches to
complete before any fan-in starts.}

\majoredits{\subsubsection{Performance}}

\majoredits{Using the same experimental setup as the prior work (i.e., encoding
the first 888 chunks of the \texttt{sintel-4k}~\mbox{\cite{sintel}} video
using 16 chunks per batch and Lambdas configured with 3GB of memory), \name{}
is 7.1\% faster than gg~\mbox{\cite{gg-atc}} and 10.5\% slower than the
original, hand-optimized ExCamera (Table~\ref{table:excamera}). The original
authors attributes the slower performance of gg ExCamera to the lack of
pre-loading which is likely also the reason for \name{}'s slower performance.}

\majoredits{But different from gg, \name{} executes orchestration in a
decentralized manner while gg has a standalone centralized coordinator on EC2.
The reduced number of network communications likely explains why \name{} is
slightly faster.}

\majoredits{Comparing with Step Functions, \name{}'s design allows the
flexibility to implement ExCamera's original application pattern where tasks
start as soon as their input data becomes available, whereas the Step
Functions implementation had to use the less-efficient Map pattern without the
flexbility to add new orchestration patterns easily. As a result, the \name{}
ExCamera enables more parallelism between branches and is 16.7\% faster than
Step Functions.}

\majoredits{\subsubsection{Cost}}

\majoredits{Different from \name{}, neither gg nor mu aimed to reduce the monetary
cost of running serverless applications and neither discussed costs in detail.
Nevertheless, there are several important factors in comparing
\name{} with gg and mu in relation to costs.}

\majoredits{First, similar to Step Functions, gg and mu both rely on standalone
orchestrators. Thus, the fundamental costs difference is also similar, namely
\name{}'s use of storage vs gg's and mu's use of VMs. mu's orchestrator
consists of a cooridnator server and a rendezvous server~\cite{excamera},
while gg's only a coordinator server~\cite{gg-atc}. mu used a 64-core VM
(\texttt{m4.16xlarge}) as the rendezvous server. Neither mu nor gg specified
the instance type of its coordinator server. However, just the cost of the
rendezvous server alone for 1 million sequential executions will be around
\$90,000 with a single \texttt{m4.16xlarge}.}

\majoredits{Furthermore, all standalone orchestrators need to separately consider
fault-tolerance in case of orchestrator failures. This will lead to
provisioning additional orchestrator instances for replication and failover.
Thus a production deployment of mu or gg will likely cost more than the setup
in the original experiments.}

\majoredits{Lastly, deploying an orchestrator per application or per user limits
the ability to amortize costs through multiplexing. A provider-hosted
orchestrator, such as Step Functions, is likely cheaper as it can
simultaneously serve many users.}