\section{Introduction}

\begin{itemize}

  \item (Serverless computing is getting increasingly
  popular~\cite{datadog-state-of-serverless} and is regarded by many as the
  next stage of the cloud computing evolution~\cite{berkeley}.)

  % \item Serverless is a new cloud computing paradigm where the system is
  % decoupled into a computation component of stateless cloud functions and
  % other stateful components such as storage, messaging, that are provided by
  % separate cloud services.

  \item \textbf{Serverless provides many benefits compared with traditional
  architecture: }

    \begin{enumerate}

      \item Fast autoscale of functions. Serverless systems can quickly start
      thousands of functions in a matter of seconds.

      % Compromise: Scalability also depends on the orchestrator service.

      \item Fine-grained billing. Users only pay for the resources used and
      can avoid paying for resources when idle.

      \item More flexible resource management that improves multiplexing and
      resource utilization. Serverless providers can reallocate resources
      immediately after computation completes and scale an application down to
      zero when idle.

      \item (Decoupled computation and storage can scale and bill
      independently)

      % Compromise: Orchestrator couples computation and storage for workflow
      % data. Scales and bills together.

      % If the orchestrator is implemented as stateless computation + data
      % stores, I'd argue it's pure serverless and therefore unum. But
      % implementing Step Function over Lambda is awkward because of Lambda
      % runtime limits.

    \end{enumerate}

  \item Recently, there have been much interests in building large serverless
  applications that consists of multiple functions with complex orchestration
  patterns such as branching on function outputs, aggregating results over
  many functions, and launch a function on the completion of one or multiple
  upstream functions~\cite{excamera, kappa, pywren, google-workflows,
  durable-functions, gg-atc}. While the original serverless offerings provide
  an API for building single functions and simple mechanisms for routing
  function results, these applications require a system that has a high-level
  interface to express workflows of serverless functions and a backend that
  can synchronize and aggregate states across functions.

  % \item \textbf{Trend in serverless applications towards more complex,
  % multi-function applications.}

  % Most existing serverless applications consist of only a single
  % function~\cite{shahrad-azure}. Recently, there have been multiple efforts to
  % build more complex, multi-function applications on
  % serverless~\cite{excamera, kappa, triggerflow, pywren, google-workflows,
  % durable-functions, gg-atc}.

  % \item \textbf{What do these applications require differently and what is
  % serverless workflow}

  % Different from the original single-function applications, multi-function
  % applications also require the serverless system to be able to express and
  % manage complex function interactions, such as branching, fan-out, and
  % fan-in. They are not simple "group-togethers" of functions; Instead, they
  % are workflows made up of independent functions that interact with each other
  % in various different patterns~\cite{aws-step-functions, durable-functions,
  % icpe-2020, ieee-fakhfakh, cloudburst}.


  \item (Many serverless workflow systems have emerged to meet this need.)


  \item \textbf{Unfortunately, these solutions all break out of the serverless
  paradigm and turn back to the traditional SaaS/PaaS architecture.}

  Workflows on these systems are written with a set of \emph{specialized APIs}
  and executed by \emph{purpose-built, centralized hosted services}
  (often called controllers, executors, coordinator or
  orchestrators)~\cite{gg-atc, excamera, kappa, triggerflow, pywren,
  durable-functions, aws-step-functions, google-cloud-composer,
  google-workflows}.

  \item \textbf{Downsides of the orchestrator design approach}

    \begin{enumerate}
      \item \textbf{Costs of an additional hosted service.} Adding additional
      services to the serverless environment takes significant effort and
      resources in terms of both developement and maintenance. Long-running
      orchestrators requires reserved resources and a team of engineers
      on-call.

      \item \textbf{Cannot leverage the benefits of serverless.} Relying on a
      centralized hosted service to drive workflows compromises important
      benefits of using a serverless system.

        \begin{enumerate}

          \item Scalability of workflows also depends on the performance of
          the orchestrator service. A slow orchestrator can become the
          bottleneck and nullify the fast autoscale advantage of serverless.
          Service providers need to make sure the orchestrator's performance
          match that of the serverless system.

          \item During execution, needs to run one orchestrator instance
          \emph{per workflow invocation} and the instance needs to stay around
          until all functions in the workflow complete, including idle time
          while waiting for functions to return results. This leads to reduced
          resource utilization as the service provider has to reserve the
          orchestrator's resources for the entire duration of the workflow
          even when the orchestrator is not doing useful work.

          \item Service providers pass the costs to users. Users are not
          billed in fine granularity solely for the resources used but also
          pay for orchestrators idle time (double billing).

          For examples, Step Functions bills based the number of state
          transitions (approx. the number of function invocations). Google
          Cloud Composer bills on orchestrator runtime on 10-min increments.
          In comparison, Google Cloud Functions are billed in 100ms
          increments. Azure Durable Functions uses a preempt and restore
          strategy to alleviate waiting and double billing, but users are
          billed whenever an orchestrator is restored (essentially you're
          billed for the occurance of idleness instead of the duration of
          idleness).

        \end{enumerate}

    \end{enumerate}


  % \item \textbf{In this paper, we examine whether it is possible to build
  % complex multi-function serverless workflows purely within the serverless
  % abstraction.}

  % \emph{Is the new paradigm capable of supporting complex applications on its
  % own or does it have to rely on traditionally-architectured services?}
  \item \textbf{In this paper, we demonstrate a new approach to enabling
  serverless workflows that are built purely within the serverless
  abstraction.} Our approach transforms high-level representations of complex
  serverless workflows (e.g., Step Functions) into functions that are
  executable on existing serverless platforms. With a runtime library, each
  function runs a subset of the workflow such that the collection of all
  functions execute the entire workflow without relying on any additional
  services.

  \item \textbf{High-level description of \name{}}

    \begin{enumerate}

      \item We build a system called \name{} that is capable of running
      complex workflows entirely within a serverless environment.

      \item \name{} consists of a suite of frontend compilers, a
      continuation-based intermediary representation and a runtime library.

      \item The frontend compilers can transform applications written for
      existing workflow systems (e.g., AWS Step Functions) into the
      continuation-based
      \name{} IR.

      \item We show that with the IR, we can distribute workflow actions onto
      component functions in an application. And a runtime library packaged
      with each function can then perform the assigned workflow action.

      \item \name{} supports stateful actions, such as fan-out, fold, with a
      named data store shared among functions.  We show that it is possible to
      manage runtime states with any storage \emph{as long as function outputs
      are uniquely named and the storage supports querying items with names
      (e.g., databases, KV stores, object stores, etc.)}.
    \end{enumerate}

  \item \textbf{Benefits}
    \begin{enumerate}
      \item Removes the effort to build and maintain specialized hosted
      workflow services
      \item Not being part of the underlying system, a library is easier to
      change, adapt and be portable.
      \item \emph{Ability to leverage the advantages of serverless:}
        \begin{itemize}
          \item Cheaper -> a proxy for resource utilization
          \item (Not sure about this one) Orchestration is automatically
          parallelized. Can potentially demonstrate if \name{} consistently
          outperforms Step Functions on highly-parallel applications.
          \emph{This is not to claim that Step Functions are fundamentally
          unscalable, but that because we build on top of a highly-scalable
          system (Lambda), the application just scales with that one Lambda
          API, instead of having to rely on an additional system (which is
          Step Function in this case) for its scalability.}
        \end{itemize}
    \end{enumerate}

  \item \textbf{Contribution}
    \begin{enumerate}
      \item Show that it is possible to support workflows entirely with
      serverless. --> \emph{Strengthens the case for serverless in general and
      explore the boundary of serverless capability}.
      \item (Result-dependent) Overhead of \name{} library is actually low. So
      this is not terrible idea from a performance standpoint.
    \end{enumerate}


%   \item \textbf{In this paper, we argue that building cloud workflows with serverless
% does not require specialized orchestrators. Instead, orchestration logic can
% be distributed to and executed as a \emph{library} on component functions.}

%   \item We show that given workflow definitions written for existing systems,
%   a significant portion of the workflow states can be derived statically and
%   encoded as a \emph{continuation-based intermediary representation}.

%   \item The advantage of the continuation-based IR is that it is
%   platform-independent and that the continuations can be distributed to
%   component functions.

%   \item A runtime library is packaged with each function. The library executes
%   the continuations and makes sure each function's output is uniquely named.

%   \item We show that it is possible to manage runtime states with any storage
%   as long as function outputs are uniquely named and the storage supports
%   querying items with names (e.g., databases, KV stores, object stores, etc.).

%   \item Benefits:

%     \begin{enumerate}

%       \item Orchestration is distributed to component functions and
%       automatically parallelized.

%       \item Each function only processes the data it needs. Data only flow
%       through the function that requires it, which reduces the amount of
%       network communication.

%       \item Removes the need of building and maintaining specialized
%       orchestrators.

%       \item Complete separation of compute (serverless) and storage. Workflows
%       can then automatically scale with the serverless system and the storage
%       system.

%       \item (Run on any environment that has a serverless offering and a named
%       storage.) (Easier to support different platforms by writing library than
%       building a specialized workflow system)

%       \item IR can express workflows that existing workflow languages
%       cannot/awkward to express.

%     \end{enumerate}

%   \item We implement a system called \name{} that consists of a suite of
%   frontend compilers, an IR and runtime libraries.

%   \begin{enumerate}
%     \item supports workflows written in AWS Step Functions (state machine),
%   Google Cloud Composer (DAG) and PyWren (procedural code)

%     \item Runtime library that can execute workflows on AWS, Azure (and Google Cloud).

%     \item supports all of the workflow features of Step Functions and GCC.
%       % chain, branch, catch-and-retry, map, parallel

%     \item Execution guarantee: at-least once, not worse than existing systems.
%   (Maybe can do exactly-once for internal states with a strongly consistent
%   storage and checkpointing on)

%     \item Performance highlights: 1. runtime overhead (latency and memory) 2.
%     latency comparison (improvements) with Step Functions (Durable Functions,
%     GCC).
%   \end{enumerate}

\end{itemize}


% Distributing coordination via a Continuation-passing style IR and runtime.
% Contribution: identified the necessary states that needs to be passed around.
% Identify what states can be generated static at compile-time (and then just
% save as a configuration file) and what states can only be known at runtime.
% This step is fundamental for distributing coordination.

% Alternative story lines: 
% 1. The approach is reminisent of traditional workflow systems
% 2. Lessons previously from building stateful distributed applications cannot be applied in serverless (CAN WE MAKE THIS ARGUMENT?)



