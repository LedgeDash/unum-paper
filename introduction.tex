\section{Introduction}\label{sec:intro}

Serverless computing offers a simple but powerful abstraction consisting of
stateless compute components (Functions as a Service, or FaaS) and scalable,
multi-tenant data stores~\cite{berkeley}. Developers build applications using
task-specific, event-driven ``functions'' without the need to provision or
manage servers. In turn, serverless platforms have been able to offer high
burst-scalability and quickly reclaim function resources as soon as they are
idle. Developers are charged in small compute and storage increments (100s of
milliseconds and per-stored-object and request, respectively), and platforms
can make efficient use of hardware resources.

Because serverless computing builds on ubiquitous existing cloud
infrastructure---scalable and performant storage and workload scheduling---it is
able to expose highly granular access to datacenter resources with relatively
low overhead and end-user cost. Moreover, this design simplicity has meant that
public cloud providers have been able to rapidly develop and deploy similar
offerings, along with numerous open source solutions deployed in private cloud
settings~\cite{aws-lambda,gcp-functions,azure-functions,openwhisk,openfaas}.

Originally, serverless platforms targeted simple applications with one or a few
functions and no, or only simple interaction between them. Recently, though,
this paradigm has increasingly proven useful for more complex applications
composed of many functions with rich, stateful, interaction
patterns~\cite{excamera, pywren, gg-atc, beldi, boki}. Unfortunately, building
such applications using basic serverless building blocks is challenging.  Due to
the event driven nature of FaaS functions, fan-in interaction patterns (e.g.\
aggregations or folds) are difficult to express. Moreover, implementing such
patterns correctly is hard as FaaS platforms may attempt to execute a function
invocation more than once, due to lost messages, infrastructure failures, or
inconsistency in invocation queues, and individual functions may be
non-deterministic.  Finally, intermediate states must be managed efficiently and
deleted promptly to avoid incurring unbounded storage costs over repeated
executions of a workflow.

In order to support complex FaaS applications, cloud providers have built and
deployed specialized centralized workflow
orchestrators~\cite{aws-step-functions, google-cloud-composer, google-workflows,
durable-functions}. Developers provide a description of an execution
graph---nodes in the graph represent FaaS functions and edges represent
invocations of a function with the output of one or more functions---while the
orchestrator drives the execution of this graph and hosts the state of execution
(outstanding invocations and intermediate results) centrally.

Centralization makes supporting complex interactions simple---e.g.\ an
orchestrator can support fan-in by simply waiting for all branches to complete
before invoking an aggregation function. Similarly, a centralized orchestrator
can ensure that workflow results are consistent with an exactly-once execution
by simply choosing one result for each function invocation in the workflow, even
if some functions are executed multiple times and return different results. As a
result, these orchestrators can offer high-level programming interfaces that
express complex function interactions while promising that workflow results are
consistent even if individual function invocations execute more than once.

In principle, developers could deploy their own orchestrators, written as
sequential programs running on a dedicated machine function. However, such a
solution isn't tolerant to faults in the orchestrator and does not provide burst
scalability to many workflow invocations. Instead, application developers
typically rely on a multi-tenant orchestration service run by the cloud provider
that amortizes the engineering and resource cost of making orchestration fault
tolerant, correct, and scalable. In turn, these overheads are typically
reflected in high end-user prices compared to invoking FaaS functions natively.

These orchestration services make design decisions, e.g., about which
interactions to support and execution semantics to provide, that fit many, but
not all applications. This results in a compromise familiar from operating
systems~\cite{exokernel,spin}, networks~\cite{active-networks,sdn}, and storage
systems~\cite{comet,splinter}---well designed centralized systems efficiently
support the needs of many applications but cannot meet all application needs.
%
%Indeed, researchers have devised new orchestrators to support FaaS applications
%that cannot be efficiently run using existing
%orchestrators~\cite{excamera,gg-atc}.

In this paper, we try to answer a simple question: \textit{is centralization
\emph{necessary} to achieve the benefits of workflow  orchestrators?} We argue
it is not. In particular, the scalable and strongly consistent datastores
already provided as a basis for serverless platforms resolve the hardest
challenge of centralization: coordination. Using such datastores, we show that a
decentralized orchestrator can achieve strong execution guarantees and run
complex execution graphs efficiently. We argue that decentralizing orchestration
is better for cloud providers as they need not develop and maintain yet another
complex service. It is better for developers as it gives applications more
flexibility to use more performant, applications-specific orchestration
optimizations and makes porting applications between different cloud platforms
easier.

To support these arguments, we present \name{}, a system for decentralized
serverless workflow orchestration (\S\ref{sec:design}). \name{} provides
orchestration as a library that runs in-situ with user defined FaaS functions,
rather than as a separate service. The library relies on a minimal set of
existing serverless APIs---function invocation and a few basic datastore
operations---that are common across cloud platforms. \name{} introduces an
intermediate representation (IR) language to express interactions execution
graphs using only node-local information while supporting front-end compilers
that can transform high-level workflow descriptions into the IR.

At a high level, \name{} relies on the FaaS scheduler to run each function
invocation \emph{at least} once and consistent datastore operations to
coordinate interactions and deduplicate multiple executions of the same function
invocation. The key design challenge in \name{} is to provide these properties
in a decentralized yet efficient manner using a minimal set of underlying
serverless APIs.

\name{} fan-ins use objects in a consistent datastore as a coordination point
for fan-in branches. \name{} ensures workflow correctness despite multiple
executions of non-deterministic functions by using checkpoints to commit to
exactly one output for a function invocation. Both require generating globally
unique names for nodes and edges in the execution graph \emph{locally} (using
information available at each node locally) as well as cleaning up intermediate
datastore objects in a timely manner.

Our implementation of \name{} (\S\ref{sec:impl}) includes a compiler for AWS Step
Functions' description language, enabling \name{} to run arbitrary Step Function
workflows.  We show that Step Function workflows compiled to \name{} execute
with the same execution semantics and fault-tolerance as running natively using
the Step Functions centralized orchestrator.

Moreover, while both performance and cost are difficult to compare objectively
with existing black-box production orchestrators---both are influenced by
deployment and pricing decisions that may not reflect the underlying efficiency
or cost of the system---\name{} performs well in practice (\S\ref{sec:eval}). We
find that a representative set of applications scale better with \name{} than
AWS Step Functions, typically complete faster low scale, and cost
significantly less (by over an order of magnitude) to run. We also demonstrate
that \name{}'s IR allows hand-tuned applications to run faster than their Step
Functions equivalent by using application-specific optimizations and supporting
a richer set of interaction patterns.
