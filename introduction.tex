\section{Introduction}\label{sec:intro}

\remove{Serverless computing offers a simple but powerful abstraction
consisting of stateless compute components (Functions-as-a-Service, or FaaS)
and scalable, multi-tenant data stores~\mbox{\cite{berkeley}}. Developers
build applications using task-specific, event-driven ``functions'' without the
need to provision or manage servers. Serverless computing builds on ubiquitous
existing cloud infrastructure---scalable and performant storage and workload
scheduling---so is able to expose highly granular access to datacenter
resources with relatively low overhead and end-user cost.}

\majoredits{Serverless computing offers a simple but powerful abstraction with
two essential components: a stateless compute engine (Functions as a Service,
or FaaS) and a scalable, multi-tenant data store~\cite{berkeley}. Developers
build applications using stateless, event-driven ``functions'' which persist
states in shared data stores. This abstraction allows users to leverage
scalable datacenter resources with fine-grained pay-for-what-you-use billing
and frees them from server administration.}

\remove{Developers build applications using task-specific, event-driven
``functions'' without the need to provision or manage servers. Serverless
computing builds on ubiquitous existing cloud infrastructure---scalable and
performant storage and workload scheduling---so is able to expose highly
granular access to datacenter resources with relatively low overhead and
end-user cost.}

\remove{As a result, serverless platforms have been able to offer high
burst-scalability and quickly reclaim function resources as soon as they are
idle~\mbox{~\cite{aws-lambda,gcp-functions,azure-functions,openwhisk,openfaas}}.
Developers are charged in small compute and storage increments (100s of
milliseconds and per-stored-object and request, respectively), and platforms
can make efficient use of hardware resources.}


While serverless platforms originally targeted simple applications with one or
a few functions, this paradigm has increasingly proven useful for more complex
applications composed of many functions with rich and often stateful
interaction patterns~\cite{excamera, pywren, gg-atc, beldi, boki}.
Unfortunately, building such applications using basic serverless building
blocks is challenging. At-least-once execution guarantees mean functions with
a non-deterministic output may pass inconsistent results to downstream
functions. Event-driven execution makes depending on the results of multiple
previous functions challenging. Finally, intermediate states must be managed
efficiently and deleted promptly to avoid incurring unbounded storage costs
over repeated executions of a workflow.

\remove{Cloud providers have deployed specialized centralized workflow
orchestrators~\mbox{\cite{aws-step-functions, google-cloud-composer,
google-workflows, durable-functions}} to support such applications. Developers
provide a description of an execution graph---nodes in the graph represent
FaaS functions and edges represent invocations of a function with the output
of one or more functions---while the orchestrator drives the execution of this
graph and hosts the state of execution (outstanding invocations and
intermediate results) centrally.}

\majoredits{Cloud providers and application developers have introduced
standalone workflow orchestrators to support such applications
(\S\ref{sec:bg:orchestrator}). Typically, cloud providers offer serverless
orchestrators as a service~\cite{aws-step-functions, google-cloud-composer,
google-workflows, durable-functions}, though users may build custom
orchestrators~\cite{temporal, gg-atc, excamera} and deploy them in separate
VMs or containers alongside their functions.}

\majoredits{Although they are often internally distributed, standalone
orchestrators work as \emph{logically centralized} controllers. Developers
provide a description of an execution graph---nodes in the graph represent
FaaS functions and edges represent invocations of a function with the output
of one or more functions---while the orchestrator drives the execution of this
graph by invoking functions, receiving function results and storing
intermediate states (e.g., outstanding invocations and intermediate results)
centrally.}

Centralization makes supporting complex interactions simple---e.g.\ an
orchestrator can support fan-in patterns by simply waiting for all branches to
complete before invoking an aggregation function. Similarly, a centralized
orchestrator can ensure that workflow results appear to be the result of
executing each constituent function exactly-once by choosing one result for
each function invocation. \remove{Finally, centralizing orchestration into a
multi-tenant service amortizes the engineering and resource cost of making
such a service fault tolerant, correct, and scalable. As a result, these
orchestrators can offer high-level programming interfaces that express complex
function interactions while promising that workflow results are consistent
even if individual function invocations execute more than once.}\dhl{not sure
if striked-out text is relevant enough to our argument to be in Intro. In
particular, why amortizing the costs \emph{causes} ("As a result")
orchestrators to offer high-level programming interfaces and exactly-once
guarantees.}

\remove{However, centralized orchestrators also preclude users from making their
own trade-offs between available interactions or execution guarantees and
performance, resource overhead, scalability and expressiveness. For example,
an application with some deterministic functions in their workflow may not be
able to reap performance benefits for those functions. This results in a
compromise familiar from operating systems~\mbox{\cite{exokernel,spin}},
networks~\mbox{\cite{active-networks,sdn}}, and storage
systems~\mbox{\cite{comet,splinter}}---well designed centralized systems
efficiently support the needs of many applications but cannot meet all
application needs.}

\majoredits{However, standalone orchestrators have important drawbacks for both
serverless providers and serverless users. As an additional service that is
critical to application performance and correctness, a standalone orchestrator
is expensive to build, host and scale. User-deployed orchestrators risk
under-utilization and do not benefit from serverless' fine-grained billing and
freedom from server management. Provider-hosted orchestrators are multi-tenant
and can thus multiplex over many users to improve resource utilization and
amortize the cost. However, they still incur the expenses of dedicated
hardware resources and on-call engineering teams.

Furthermore, standalone orchestrators preclude users from making
application-specific trade-offs and optimizations. While the interface and
implementation of an orchestrator might efficiently support the needs of many
applications, it cannot meet all applications' needs, resulting in a
compromise familiar from operating systems~\cite{exokernel,spin},
networks~\cite{active-networks,sdn}, and storage
systems~\cite{comet,splinter}.}

\majoredits{For example, applications that need orchestration patterns not
supported by the provider-hosted orchestrator have to either compromise
performance by using less-efficient patterns or first repeat the
hard work of building, deploying and managing their own custom
orchestrator~(\S~\ref{sec:eval:excamera}). Similarly, an application with
deterministic functions, which requires weaker execution guarantees, may not
be able to reap performance benefits if the orchestrator service only supports
strong exactly-once execution.}

\remove{In this paper, we try to answer a simple question: is centralization
necessary to achieve the benefits of workflow  orchestrators? We argue it is
not. In particular, scalable and strongly consistent datastores, which already
serve as a critical component of serverless platforms, resolve the hardest
challenge of centralization: coordination. Using such datastores, we show that
a decentralized orchestrator can achieve strong execution guarantees and run
complex execution graphs efficiently. We argue that decentralizing
orchestration is better for cloud providers as they need not develop and
maintain yet another complex service. It is better for developers as it gives
applications more flexibility to use more performant, applications-specific
orchestration optimizations and makes porting
applications between different cloud platforms easier.}

\majoredits{In this paper, we show that additional standalone orchestrators for
serverless applications are unnecessary. Furthermore, we argue that
decentralized, application-level orchestration is better for both serverless
providers and serverless users. It is better for cloud providers as they need
not host and maintain yet another complex service, saving engineering and
hardware resources. It is better for applications as it gives them more
flexibility to implement custom patterns as needed and apply
application-specific optimizations in orchestration. Moreover, as cloud
providers improve the performance of essential serverless components,
application-level orchestration built on top of those services benefit
automatically.}

To support these arguments, we present \name{}, a system for
decentralized\majoredits{, application-level} serverless workflow orchestration
(\S\ref{sec:design}). \name{} provides orchestration as a library that runs
\emph{in-situ} with user-defined FaaS functions, rather than as a
\remove{separate}\majoredits{standalone} service. The library relies on a minimal
set of existing serverless APIs---function invocation and a few basic
datastore operations---that are common across cloud platforms. \name{}
introduces an intermediate representation (IR) language to express execution
graphs using only node-local information while supporting front-end compilers
that can transform high-level workflow descriptions into the IR.

\majoredits{A key challenge in \name{} is to support complex stateful
orchestration patterns and strong execution guarantees, in a
\emph{decentralized} manner. Our insight is that, scalable and strongly
consistent datastores, already an essential building block of serverless
applications, address the hardest challenge of centralization: coordination.
Using such datastores, we show that an application-level library running in-situ
with user functions can orchestrate complex execution graphs efficiently with
strong execution guarantees.}

\majoredits{At a high level, \name{} relies on the FaaS scheduler to run each function
invocation \emph{at least} once and consistent datastore operations to
coordinate interactions and deduplicate extra executions of the same
invocation. \name{} uses checkpoints to commit to exactly one result for a
function invocation and ensures workflow correctness despite duplicate
executions of non-deterministic functions. \name{} fan-ins use objects in
a consistent datastore as a coordination point for aggregating branches. Both
require generating globally unique names for nodes and edges in the execution
graph \emph{locally} (using only information available at each node) as well
as cleaning up intermediate datastore objects in a timely manner.}

\remove{At a high level, \name{} relies on the FaaS scheduler to run each function
invocation \emph{at least} once and consistent datastore operations to
coordinate interactions and deduplicate multiple executions of the same
function invocation. The key design challenge in \name{} is to provide these
properties in a decentralized yet efficient manner using a minimal set of
underlying serverless APIs.}

\remove{\name{} fan-ins use objects in a consistent datastore as a coordination point
for fan-in branches. \name{} ensures workflow correctness despite multiple
executions of non-deterministic functions by using checkpoints to commit to
exactly one output for a function invocation. Both require generating globally
unique names for nodes and edges in the execution graph \emph{locally} (using
information available at each node locally) as well as cleaning up intermediate
datastore objects in a timely manner.}

Our implementation of \name{} (\S\ref{sec:impl}) includes a compiler for AWS
Step Functions' description language, enabling \name{} to run arbitrary Step
Function workflows. We show that Step Function workflows compiled to \name{}
execute with the same execution guarantees as running natively using the Step
Functions orchestrator.

Moreover, while performance and cost are difficult to compare objectively with
existing black-box production orchestrators---both are influenced by
deployment and pricing decisions that may not reflect the underlying
efficiency or cost of the system---\name{} performs well in practice
(\S\ref{sec:eval}). We find that a representative set of applications scale
better, run faster, and cost significantly less with \name{} than Step
Functions. We also demonstrate that \name{}'s IR allows hand-tuned
applications to run faster by using application-specific optimizations and
supporting a richer set of interaction patterns.
