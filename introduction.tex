\section{Introduction}

\begin{itemize}

  \item (Serverless computing is getting increasingly
  popular~\cite{datadog-state-of-serverless} and is regarded by many as the
  next stage of the cloud computing evolution~\cite{berkeley}.)

  \item \textbf{Serverless provides many benefits compared with traditional
  architecture: }

    \begin{enumerate}

      \item Fast autoscale of functions. Serverless systems can quickly start
      thousands of functions in a matter of seconds.

      \item Fine-grained billing. Users only pay for the resources used and
      can avoid paying for resources when idle.

      \item More flexible resource management that improves multiplexing and
      resource utilization. Serverless providers can reallocate resources
      immediately after computation completes and scale an application down to
      zero when idle.

      \item (Decoupled computation and storage can scale and bill
      independently)

    \end{enumerate}

  \item Recently, there have been much interests in building large serverless
  applications that consists of multiple functions with complex orchestration
  patterns such as branching on function outputs, aggregating results over
  many functions, and launch a function on the completion of one or multiple
  upstream functions~\cite{excamera, kappa, pywren, google-workflows,
  durable-functions, gg-atc}. While the original serverless offerings provide
  an API for building single functions and simple mechanisms for routing
  function results, these applications require a system that has a high-level
  interface to express workflows of serverless functions and a backend that
  can synchronize and aggregate states across functions.

  \item (Many serverless workflow systems have emerged to meet this need.)

  \item \textbf{Unfortunately, these solutions all break out of the serverless
  paradigm and turn back to the traditional SaaS/PaaS architecture.}

  Workflows on these systems are written with a set of \emph{specialized APIs}
  and executed by \emph{purpose-built, centralized hosted services}
  (often called controllers, executors, coordinator or
  orchestrators)~\cite{gg-atc, excamera, kappa, triggerflow, pywren,
  durable-functions, aws-step-functions, google-cloud-composer,
  google-workflows}.

  \item \textbf{Requiring a hosted service outside the serverless environment
  is not only expensive but also fails to fully leverage the benefits of
  serverless.}

    \begin{enumerate}
      \item \textbf{Costs of an additional hosted service.} Adding additional
      services to the serverless environment takes significant effort and
      resources in terms of both developement and maintenance. Long-running
      orchestrators requires reserved resources and a team of engineers
      on-call.

      \item \textbf{Cannot leverage the benefits of serverless.} Relying on a
      centralized hosted service to drive workflows compromises important
      benefits of using a serverless system.

        \begin{enumerate}

          \item Scalability of workflows also depends on the performance of
          the orchestrator service. A slow orchestrator can become the
          bottleneck and nullify the fast autoscale advantage of serverless.
          Service providers need to make sure the orchestrator's performance
          match that of the serverless system.

          \item During execution, needs to run one orchestrator instance
          \emph{per workflow invocation} and the instance needs to stay around
          until all functions in the workflow complete, including idle time
          while waiting for functions to return results. This leads to reduced
          resource utilization as the service provider has to reserve the
          orchestrator's resources for the entire duration of the workflow
          even when the orchestrator is not doing useful work.

          \item Service providers pass the costs to users. Users are not
          billed in fine granularity solely for the resources used but also
          pay for orchestrators idle time (double billing).

          For examples, Step Functions bills based the number of state
          transitions (approx. the number of function invocations). Google
          Cloud Composer bills on orchestrator runtime on 10-min increments.
          In comparison, Google Cloud Functions are billed in 100ms
          increments. Azure Durable Functions uses a preempt and restore
          strategy to alleviate waiting and double billing, but users are
          billed whenever an orchestrator is restored (essentially you're
          billed for the occurance of idleness instead of the duration of
          idleness).

        \end{enumerate}

    \end{enumerate}

  \item \textbf{In this paper, we demonstrate a new approach to serverless
  workflows that are built purely within serverless systems.} Our approach
  transforms high-level representations of complex serverless workflows (e.g.,
  Step Functions) into functions that are executable on existing serverless
  platforms. With a runtime library, each function runs a subset of the
  workflow such that the collection of all functions execute the entire
  workflow without relying on any additional services.

  \item \textbf{High-level description of \name{}}

    \begin{enumerate}

      \item We build a system called \name{} that is capable of running
      complex workflows entirely within a serverless environment.

      \item \name{} consists of a suite of frontend compilers, a
      continuation-based intermediary representation and a runtime library.

      \item The frontend compilers can transform applications written for
      existing workflow systems (e.g., AWS Step Functions) into the
      continuation-based
      \name{} IR.

      \item We show that with the IR, we can distribute workflow actions onto
      component functions in an application. And a runtime library packaged
      with each function can then perform the assigned workflow action.

      \item \name{} supports stateful actions, such as fan-out, fold, with a
      named data store shared among functions.  We show that it is possible to
      manage runtime states with any storage \emph{as long as function outputs
      are uniquely named and the storage supports querying items with names
      (e.g., databases, KV stores, object stores, etc.)}.
    \end{enumerate}

  \item \textbf{Benefits}
    \begin{enumerate}
      \item Removes the effort to build and maintain specialized hosted
      workflow services
      \item Not being part of the underlying system, a library is easier to
      change, adapt and be portable.
      \item \emph{Ability to leverage the advantages of serverless:}
        \begin{itemize}
          \item Cheaper -> a proxy for resource utilization
          \item (Not sure about this one) Orchestration is automatically
          parallelized. Can potentially demonstrate if \name{} consistently
          outperforms Step Functions on highly-parallel applications.
          \emph{This is not to claim that Step Functions are fundamentally
          unscalable, but that because we build on top of a highly-scalable
          system (Lambda), the application just scales with that one Lambda
          API, instead of having to rely on an additional system (which is
          Step Function in this case) for its scalability.}
        \end{itemize}
    \end{enumerate}

  \item \textbf{Contribution}
    \begin{enumerate}
      \item Show that it is possible to support workflows entirely with
      serverless. --> \emph{Strengthens the case for serverless in general and
      explore the boundary of serverless capability}.
      \item (Result-dependent) Overhead of \name{} library is actually low. So
      this is not terrible idea from a performance standpoint.
    \end{enumerate}


\end{itemize}

