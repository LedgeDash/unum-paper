\section{Introduction}\label{sec:intro}

\majoredits{Serverless computing offers a simple but powerful abstraction with
two essential components: a stateless compute engine (Functions as a Service,
or FaaS) and a scalable, multi-tenant data store~\cite{berkeley}. Developers
build applications using stateless, event-driven ``functions'' which persist
states in shared data stores. This abstraction allows users to leverage
scalable datacenter resources with fine-grained pay-for-what-you-use billing
and frees them from server administration.}

While serverless platforms originally targeted simple applications with one or
a few functions, this paradigm has increasingly proven useful for more complex
applications composed of many functions with rich and often stateful
interaction patterns~\cite{excamera, pywren, gg-atc, beldi, boki}.
Unfortunately, building such applications using basic serverless building
blocks is challenging. At-least-once execution guarantees mean functions with
a non-deterministic output may pass inconsistent results to downstream
functions. Event-driven execution makes depending on the results of multiple
previous functions challenging. Finally, intermediate states must be managed
efficiently and deleted promptly to avoid incurring unbounded storage costs
over repeated executions of a workflow.

\majoredits{Cloud providers and application developers have introduced
standalone workflow orchestrators to support such applications
(\S\ref{sec:bg:orchestrator}). Typically, cloud providers offer serverless
orchestrators as a service~\cite{aws-step-functions, google-cloud-composer,
google-workflows, durable-functions}, though users may build custom
orchestrators~\cite{temporal, gg-atc, excamera} and deploy them in separate
VMs or containers alongside their functions.}

\majoredits{Although they are often internally distributed, standalone
orchestrators work as \emph{logically centralized} controllers. Developers
provide a description of an execution graph---nodes in the graph represent
FaaS functions and edges represent invocations of a function with the output
of one or more functions---while the orchestrator drives the execution of this
graph by invoking functions, receiving function results and storing
intermediate states (e.g., outstanding invocations and intermediate results)
centrally.}

Centralization makes supporting complex interactions simple---e.g.\ an
orchestrator can support fan-in patterns by simply waiting for all branches to
complete before invoking an aggregation function. Similarly, a centralized
orchestrator can ensure that workflow results appear to be the result of
executing each constituent function exactly-once by choosing one result for
each function invocation.

\majoredits{However, standalone orchestrators have important drawbacks for both
serverless providers and serverless users. As an additional service that is
critical to application performance and correctness, a standalone orchestrator
is expensive to build, host and scale. User-deployed orchestrators risk
under-utilization and do not benefit from serverless' fine-grained billing and
freedom from server management. Provider-hosted orchestrators are multi-tenant
and can thus multiplex over many users to improve resource utilization and
amortize the cost. However, they still incur the expenses of dedicated
hardware resources and on-call engineering teams.

Furthermore, standalone orchestrators preclude users from making
application-specific trade-offs and optimizations. While the interface and
implementation of an orchestrator might efficiently support the needs of many
applications, it cannot meet all applications' needs, resulting in a
compromise familiar from operating systems~\cite{exokernel,spin},
networks~\cite{active-networks,sdn}, and storage
systems~\cite{comet,splinter}.}

\majoredits{For example, applications that need orchestration patterns not
supported by the provider-hosted orchestrator have to either compromise
performance by using less-efficient patterns or first repeat the
hard work of building, deploying and managing their own custom
orchestrator~(\S~\ref{sec:eval:excamera}). Similarly, an application with
deterministic functions, which requires weaker execution guarantees, may not
be able to reap performance benefits if the orchestrator service only supports
strong exactly-once execution.}

\majoredits{In this paper, we show that additional standalone orchestrators for
serverless applications are unnecessary. Furthermore, we argue that
decentralized, application-level orchestration is better for both serverless
providers and serverless users. It is better for cloud providers as they need
not host and maintain yet another complex service, saving engineering and
hardware resources. It is better for applications as it gives them more
flexibility to implement custom patterns as needed and apply
application-specific optimizations in orchestration. Moreover, as cloud
providers improve the performance of essential serverless components,
application-level orchestration built on top of those services benefit
automatically.}

To support these arguments, we present \name{}, a system for
decentralized\majoredits{, application-level} serverless workflow
orchestration (\S\ref{sec:design}). \name{} provides orchestration as a
library that runs \emph{in-situ} with user-defined FaaS functions, rather than
as a \majoredits{standalone} service. The library relies on a minimal set of
existing serverless APIs---function invocation and a few basic datastore
operations---that are common across cloud platforms. \name{} introduces an
intermediate representation (IR) language to express execution graphs using
only node-local information while supporting front-end compilers that can
transform high-level workflow descriptions into the IR.

\majoredits{A key challenge in \name{} is to support complex stateful
orchestration patterns and strong execution guarantees, in a
\emph{decentralized} manner. Our insight is that, scalable and strongly
consistent datastores, already an essential building block of serverless
applications, address the hardest challenge of orchestration: coordination.
Using such datastores, we show that an application-level library running
in-situ with user functions can orchestrate complex execution graphs
efficiently with strong execution guarantees.}

\majoredits{At a high level, \name{} relies on the FaaS scheduler to run each
function invocation \emph{at least} once and consistent datastore operations
to coordinate interactions and deduplicate extra executions of the same
invocation. \name{} uses checkpoints to commit to exactly one result for a
function invocation and ensures workflow correctness despite duplicate
executions of non-deterministic functions. \name{} fan-ins use objects in a
consistent datastore as a coordination point for aggregating branches. Both
require generating globally unique names for nodes and edges in the execution
graph \emph{locally} (using only information available at each node) as well
as cleaning up intermediate datastore objects in a timely manner.}

Our implementation of \name{} (\S\ref{sec:impl}) includes a compiler for AWS
Step Functions' description language, enabling \name{} to run arbitrary Step
Function workflows. We show that Step Function workflows compiled to \name{}
execute with the same execution guarantees as running natively using the Step
Functions orchestrator.

Moreover, while performance and cost are difficult to compare objectively with
existing black-box production orchestrators---both are influenced by
deployment and pricing decisions that may not reflect the underlying
efficiency or cost of the system---\name{} performs well in practice
(\S\ref{sec:eval}). We find that a representative set of applications scale
better, run faster, and cost significantly less with \name{} than Step
Functions. We also demonstrate that \name{}'s IR allows hand-tuned
applications to run faster by using application-specific optimizations and
supporting a richer set of interaction patterns.
