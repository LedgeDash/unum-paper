\section{Related Work}\label{sec:related}

\paragraph{Serverless Workflows}

Many systems have recognized the need to augment serverless computing with
support for composing functions to build larger and more complex applications.
AWS Step Functions~\cite{aws-step-functions} defines serverless workflows as
state machines using a JSON schema. Google Workflows~\cite{google-workflows}
uses a YAML-based interface to list steps in a workflow sequentially and
allows jumps among steps. Azure Durable Functions~\cite{durable-functions}
uses a ``workflow-as-code'' approach, similar to driver functions, where the
workflow logic is written in a programming language (e.g., C\#, Python).

In all of these systems, orchestration is performed by a \textbf {standalone
orchestrator}. The nature and location of this component varies: in AWS Step
Functions~\cite{aws-step-functions} and Google Workflows~\cite
{google-workflows}, it is provided by a cloud service that is separately
hosted and billed. In Azure Durable Functions~\cite{durable-functions}, it is
an extension of the serverless runtime, and uses the same billing. In contrast
to all of these, \name{} proposes a novel \textbf{decentralized orchestration
strategy} and runs entirely on unmodified serverless infrastructure without
adding any new services or new components.

Kappa~\cite{kappa} addresses the lack of coordination between function and
function timeout limits when executing large applications. Similar to Durable
Functions, it also exposes a high-level programming language interface.
Cloudburst~\cite{cloudburst} uses a specialized key-value store to enable
low-latency execution of serverless functions. Users can express workflows as
static DAGs and an executor program runs the DAG by passing data and
coordinate via the key-value store. ExCamera~\cite{excamera} is parallel video
encoder running on Lambda. It is built with the mu framework which uses a
long-running coordinator to command a fleet of lambdas, each of which executes
a state machines where user functions are the states. gg~\cite{gg-atc}
proposes a thunk abstraction where each thunk executes as a lambda that has no
nondeterministic or non-idempotent behavior, and a way to program data
dependencies between thunks. gg uses a standalone coordinator to receive thunk
updates and lazily launch thunks when their inputs become available.

Similarly, the above systems rely on a standalone orchestrator program. As the
orchestrator program is not itself executing in a hosted environment, progress
is not guaranteed when its host crashes, but requires manual restart. Also,
progress is not checkpointed (except in Kappa), so workflows must restart from
the beginning in that situation. In contrast, \name{} relies only on a basic,
highly available serverless platform. Thus, it guarantees progress under all
faults, including the orchestrator. And \name{} checkpoints each function
result to minimize redundant computations when handling faults.

Beldi~\cite{beldi} and Boki~\cite{boki} are two recent systems that provide
exactly-once execution and transactions to stateful serverless applications.
Both extend transactional features to specific application side effects
supported by the system (e.g., DynamoDB writes). Developers use Beldi or
Boki's library in user code when writing to a supported data store (e.g.,
DynamoDB) such that writes are executed only once. In comparison, \name{} does
not change how developers write user code and does not extend exactly-once
guarantee to side effects in user code. Instead, \name{} treats user code as a
black box and ensures exactly-once semantics on a workflow-level. However,
\name{} users who want to ensure exactly-once when writing to DynamoDB can
additionally use Beldi or Boki in their user code.

\paragraph{Programming Interface}

Most serverless workflow systems require developers to write workflows with
specialized interfaces. Some uses a declarative approach that defines
workflows using JSON or YAML schemas (e.g., AWS Step
Functions~\cite{aws-step-functions}, Google
Workflows~\cite{google-workflows}). Others allow expressing workflow as code
(e.g., Durable Functions~\cite{durable-functions}, Kappa\cite{kappa}, Fn
Flow~\cite{fn-flow}).

\name{} does not propose a new frontend for defining workflow. Instead,
\name{} aims to support any existing frontend that explicitly or implicitly
expresses a directed graph where nodes are functions and edges are transitions
between functions. Developers using \name{} can choose the frontend that they
prefer.

%Checkpointing technique?


% \paragraph{gg}~\cite{gg-atc}

% \begin{itemize}
% 	\item Target applications are what they call "everyday tasks", including code compilation, unit testing, video encoding and object recognition
% 	\item A thunk = a x86-64 executable and its input data

% 	A thunk is deterministic. Forcing a thunk multiple times will generate the same object.

% 	Data objects are named (naming scheme 3.1.1). Reading an object might involve forcing a thunk to generate the object. A thunk's input can be references to other thunk's outputs. gg uses this mechanism to express computation graphs.

% 	Forcing a thunk multiple time will always produce the same object with the same name. To run the same function with different input needs to define a different thunk (presumably a gg compiler can help simplify the step of defining thunks that have the same executable and different input. But the paper wasn't entirely clear on this and the source code shows application-specific compilation with limited programmability.).


% 	duplicate functionalities that Lambda already provides: job scheduling, retry, timeouts.

% \end{itemize}


% \paragraph{Triggerflow}~\cite{triggerflow}
% See Section 4. implementation. Each workflow has its own workflow worker which is really a kubernetes pod. The workflow works process events and trigger actual FaaS functions.


% \paragraph{Kappa}~\cite{kappa}
% Tasks communicate with the coordinator through
% the remote procedure calls (RPCs) summarized in Table 2


% \paragraph{Cloudburst}~\cite{cloudburst}
% 1. Orthogonal: They focus on building a data store with specialized APIs and consistency models for faas workflow
% 2. Differennt programming interface (TODO: more details)
% 3. Not built on real faas platform; can't run on aws, azure or google cloud


% \paragraph{mu and Excamera}~\cite{excamera}

% \paragraph{Boki}


% \paragraph{PyWren}~\cite{pywren}

% \paragraph{Beldi}

% Target applications whose \emph{constituent} functions are stateful, basically meaning that they write to DynamoDB, and Beldi wrappers around those DynamoDB writes to provide transactional semantics.

% not an actual workflow system because there is not interface to write
% workflows. The system is really a library that provides transactions for
% functions if they write their data to DynamoDB. Functions import and use the
% Beldi library directly in their code. Here is an example:
% https://github.com/eniac/Beldi/blob/master/internal/media/core/movieId.go

% To chain functions F->G, F's code has to include a invoke call to G. This is
% not too different from triggers and unstructured composition which leads to
% scattered control flow and spagetti code.

% Also, it doesn't seem to provide a way to do aggregation. For example, how do
% you do fan-in or fold in Beldi.

% Boki is similar. There's no interface to define workflow

% https://github.com/ut-osa/boki-benchmarks/tree/main/experiments/workflow

% Execution guarantee comparison. Can provide exactly-once guarantee on some of
% the external operations, but not all.

% Even though they claim asyn invoke API is exactly-once, that's just not true.
% Lambda doesn't even guarantee exactly-once execution.

% \name{} requries fewer features from the data store: don't need scan, filter
% or projection.


% Google Cloud Composer uses Airflow.
% https://github.com/apache/airflow/tree/main/airflow/example_dags
% https://cloud.google.com/composer/docs/samples

% Azure Durable Functions. https://docs.microsoft.com/en-us/learn/modules/create-long-running-serverless-workflow-with-durable-functions/

% Google Cloud Workflows.
% Example: https://codelabs.developers.google.com/codelabs/cloud-workflows-intro
% https://cloud.google.com/workflows
% Repository: https://cloud.google.com/workflows/docs/samples

 
% https://github.com/serverlessworkflow/specification/tree/main/examples



% https://github.com/kalevalp/hello-retail-baseline


% ExCamera or mu:

% all workers in mu use the same generic Lambda function that is capable of
% executing the work of any thread in the computation. (change the programming
% interface: developers not writing individual functions anymore. :"To design a
% computation, a user specifies each worker’s sequence of RPC re- quests and
% responses in the form of a finite-state machine (FSM), which the coordinator
% executes.")

% mu uses a long-lived coordinator that commands and controls a fleet of
% workers. The coordinator steps workers through their tasks by issuing RPC
% requests and processing responses. As examples, the coordinator can instruct
% the worker to re- trieve from or upload to AWS S3; establish connections to
% other workers via a rendezvous server; send data to workers over such
% connections; or run an executable.

% Do the output of one worker go through the coordinator to be sent to and
% consumed by another worker? No, there's a separate rendezvous server for
% worker communication. Like the coordinator, the rendezvous server is long
% lived. mu’s rendezvous is a simple relay server that stores messages from
% workers and forwards them to their destination.


% gg's Restrictions on user code: "gg thunks are designed to be deterministic."
% "it is not allowed to use the network or access unlisted objects or files." So
% functions are basically pure so that gg doesn't need to reason about
% exactly-once semantics.


% "In a long chain
% of rebasing, later threads spend much of their time waiting
% on predecessors (Figure 4). A more-sophisticated launch-
% ing strategy could save money, without compromising
% completion time, by delaying launching these threads."

% [This is another point about many of these frameworks, (I think cloudburst has
% this problem as well) that they need to launch custom-built containers *ahead
% of time*, not on-demand, not event-driven. Double billing becomes an issue.
% Utilization becomes an issue.]


%------------------------

% In the case of orchestrators/coordinators, functions call back to the
% orchestrator when complete and the orchestrator decides what to do next: which
% downstream function to invoke:

% mu: "mu uses a long-lived coordinator that commands and controls a fleet of
% workers."

% gg: "The main entry-point for executing a thunk is the coordinator program....
% Upon start, this program [the coordinator] materializes the target thunk's
% dependency graph... Then, the thunks that are ready to execute are passed to
% execution engines. ... When the execution of a thunk is done, the progra      m [the
% coordinator] updates the graph by replacing the references to the just-forced
% thunk ... The thunks that become ready to execute are placed on a queue and
% passed to the execution engines when their capacity permits."
