\section{Related Work}\label{sec:related}

\paragraph{Destination and triggers}

Compare with continuations in unum.




Overall characteristics of orchestrator based engines: The orchestrator
performs function invocations; functions send results back to correct the
orchestrator instance.

Why does this characterstics matter?

Questions:

\begin{itemize}
	\item Is it pure serverless? What does pure serverless mean?
	\item Any performance comparisons necessary?
\end{itemize}

\paragraph{gg}~\cite{gg-atc}

\begin{itemize}
	\item Target applications are what they call "everyday tasks", including code compilation, unit testing, video encoding and object recognition
	\item A thunk = a x86-64 executable and its input data

	A thunk is deterministic. Forcing a thunk multiple times will generate the same object.

	Data objects are named (naming scheme 3.1.1). Reading an object might involve forcing a thunk to generate the object. A thunk's input can be references to other thunk's outputs. gg uses this mechanism to express computation graphs.

	Forcing a thunk multiple time will always produce the same object with the same name. To run the same function with different input needs to define a different thunk (presumably a gg compiler can help simplify the step of defining thunks that have the same executable and different input. But the paper wasn't entirely clear on this and the source code shows application-specific compilation with limited programmability.).


	duplicate functionalities that Lambda already provides: job scheduling, retry, timeouts.



\end{itemize}


\paragraph{Triggerflow}~\cite{triggerflow}
See Section 4. implementation. Each workflow has its own workflow worker which is really a kubernetes pod. The workflow works process events and trigger actual FaaS functions.


\paragraph{Kappa}~\cite{kappa}
Tasks communicate with the coordinator through
the remote procedure calls (RPCs) summarized in Table 2


\paragraph{Cloudburst}~\cite{cloudburst}
1. Orthogonal: They focus on building a data store with specialized APIs and consistency models for faas workflow
2. Differennt programming interface (TODO: more details)
3. Not built on real faas platform; can't run on aws, azure or google cloud


\paragraph{mu and Excamera}~\cite{excamera}

\paragraph{Boki}


\paragraph{PyWren}~\cite{pywren}

\paragraph{Beldi}

Target applications whose \emph{constituent} functions are stateful, basically meaning that they write to DynamoDB, and Beldi wrappers around those DynamoDB writes to provide transactional semantics.

not an actual workflow system because there is not interface to write
workflows. The system is really a library that provides transactions for
functions if they write their data to DynamoDB. Functions import and use the
Beldi library directly in their code. Here is an example:
https://github.com/eniac/Beldi/blob/master/internal/media/core/movieId.go

To chain functions F->G, F's code has to include a invoke call to G. This is
not too different from triggers and unstructured composition which leads to
scattered control flow and spagetti code.

Also, it doesn't seem to provide a way to do aggregation. For example, how do
you do fan-in or fold in Beldi.

Boki is similar. There's no interface to define workflow

https://github.com/ut-osa/boki-benchmarks/tree/main/experiments/workflow

Execution guarantee comparison. Can provide exactly-once guarantee on some of
the external operations, but not all.

Even though they claim asyn invoke API is exactly-once, that's just not true.
Lambda doesn't even guarantee exactly-once execution.

\name{} requries fewer features from the data store: don't need scan, filter
or projection.


% Google Cloud Composer uses Airflow.
% https://github.com/apache/airflow/tree/main/airflow/example_dags
% https://cloud.google.com/composer/docs/samples

% Azure Durable Functions. https://docs.microsoft.com/en-us/learn/modules/create-long-running-serverless-workflow-with-durable-functions/

% Google Cloud Workflows.
% Example: https://codelabs.developers.google.com/codelabs/cloud-workflows-intro
% https://cloud.google.com/workflows
% Repository: https://cloud.google.com/workflows/docs/samples

 
% https://github.com/serverlessworkflow/specification/tree/main/examples



% https://github.com/kalevalp/hello-retail-baseline


% ExCamera or mu:

% all workers in mu use the same generic Lambda function that is capable of
% executing the work of any thread in the computation. (change the programming
% interface: developers not writing individual functions anymore. :"To design a
% computation, a user specifies each worker’s sequence of RPC re- quests and
% responses in the form of a finite-state machine (FSM), which the coordinator
% executes.")

% mu uses a long-lived coordinator that commands and controls a fleet of
% workers. The coordinator steps workers through their tasks by issuing RPC
% requests and processing responses. As examples, the coordinator can instruct
% the worker to re- trieve from or upload to AWS S3; establish connections to
% other workers via a rendezvous server; send data to workers over such
% connections; or run an executable.

% Do the output of one worker go through the coordinator to be sent to and
% consumed by another worker? No, there's a separate rendezvous server for
% worker communication. Like the coordinator, the rendezvous server is long
% lived. mu’s rendezvous is a simple relay server that stores messages from
% workers and forwards them to their destination.


% gg's Restrictions on user code: "gg thunks are designed to be deterministic."
% "it is not allowed to use the network or access unlisted objects or files." So
% functions are basically pure so that gg doesn't need to reason about
% exactly-once semantics.


% "In a long chain
% of rebasing, later threads spend much of their time waiting
% on predecessors (Figure 4). A more-sophisticated launch-
% ing strategy could save money, without compromising
% completion time, by delaying launching these threads."

% [This is another point about many of these frameworks, (I think cloudburst has
% this problem as well) that they need to launch custom-built containers *ahead
% of time*, not on-demand, not event-driven. Double billing becomes an issue.
% Utilization becomes an issue.]


%------------------------

% In the case of orchestrators/coordinators, functions call back to the
% orchestrator when complete and the orchestrator decides what to do next: which
% downstream function to invoke:

% mu: "mu uses a long-lived coordinator that commands and controls a fleet of
% workers."

% gg: "The main entry-point for executing a thunk is the coordinator program....
% Upon start, this program [the coordinator] materializes the target thunk's
% dependency graph... Then, the thunks that are ready to execute are passed to
% execution engines. ... When the execution of a thunk is done, the progra      m [the
% coordinator] updates the graph by replacing the references to the just-forced
% thunk ... The thunks that become ready to execute are placed on a queue and
% passed to the execution engines when their capacity permits."

% Step Functions: TBA


% unum's different: orchestration logic is distributed to each function. When a
% function complete, instead of calling back to a long-lived coordinator, the
% unum runtime on the Lambda decides what to do next. This design eliminates the
% need for a separate long-running service that executes workflows. Saves a
% communication trip back to the orchestrator.

